{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from configs import project_config\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalLSTMTSPostMeanScoreMatching  import \\\n",
    "    ConditionalLSTMTSPostMeanScoreMatching\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "from src.classes.ClassFractionalLorenz96 import FractionalLorenz96\n",
    "from configs.RecursiveVPSDE.LSTM_4DLorenz.recursive_LSTM_PostMeanScore_4DLorenz_T256_H05_tl_110data import get_config\n",
    "config = get_config()\n",
    "num_time_steps = 10\n",
    "num_paths = 3\n",
    "fLnz = FractionalLorenz96(X0=np.array(config.initState), diff=config.diffusion, forcing_const=config.forcing_const,\n",
    "                              num_dims=config.ndims)\n",
    "Xs = np.array(\n",
    "        [fLnz.euler_simulation(H=config.hurst, N=num_time_steps, deltaT=config.deltaT, X0=np.array(config.initState), Ms=None, gaussRvs=None,\n",
    "                               t0=config.t0, t1=config.t0*config.deltaT) for _ in (range(num_paths))]).reshape((num_paths, num_time_steps+1, config.ndims))\n",
    "Xs = Xs[:, np.random.choice(np.arange(Xs.shape[1]),size=1)[0], :]\n",
    "print(Xs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from configs.RecursiveVPSDE.LSTM_4DLorenz.recursive_LSTM_PostMeanScore_4DLorenz_T256_H05_tl_110data import get_config\n",
    "config = get_config()\n",
    "sim_data = np.load(config.data_path, allow_pickle=True)\n",
    "sim_data_tensor = torch.tensor(sim_data, dtype=torch.float)\n",
    "#dX_dims = [np.diff(Xs_i)[0] / 250 for Xs_i in [Xs0, Xs1, ..., Xs_{D-1}]]\n",
    "device = \"cpu\"\n",
    "PM = ConditionalLSTMTSPostMeanScoreMatching(*config.model_parameters).to(device)\n",
    "dX_global = 1./1000\n",
    "def process_single_threshold(x):\n",
    "    diff = sim_data_tensor - x.reshape(1,-1)  # shape: (M, N, D)\n",
    "    mask = torch.all((diff <= dX_global) & (diff >= -dX_global), dim=-1)\n",
    "    # Get indices where mask is True (each index is [i, j])\n",
    "    indices = mask.nonzero(as_tuple=False)\n",
    "    sequences = []\n",
    "    js = []\n",
    "    for idx in indices:\n",
    "        i, j = idx.tolist()\n",
    "        # Extract the sequence: row i, columns 0 to j (inclusive)\n",
    "        seq = sim_data_tensor[i, :j + 1, :]\n",
    "        sequences.append(seq)\n",
    "        js.append(len(seq))\n",
    "    outputs = []\n",
    "    if sequences:\n",
    "        # Pad sequences to create a batch.\n",
    "        # pad_sequence returns tensor of shape (batch_size, max_seq_len)\n",
    "        padded_batch = pad_sequence(sequences, batch_first=True, padding_value=torch.nan).to(device)\n",
    "        # Add feature dimension: now shape becomes (batch_size, max_seq_len, 1)\n",
    "        #padded_batch = padded_batch.unsqueeze(-1).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_output, _ = PM.rnn(padded_batch, None)\n",
    "        outputs = batch_output[torch.arange(batch_output.shape[0]), torch.tensor(js, dtype=torch.long) - 1,\n",
    "                  :].unsqueeze(1).cpu()\n",
    "    return x, outputs\n",
    "\n",
    "# Option 1: Process sequentially (using tqdm)\n",
    "features_Xs = {}\n",
    "for i in range(Xs.shape[0]):\n",
    "    x = Xs[i, :].reshape(-1, 1)\n",
    "    x_val, out = process_single_threshold(x)\n",
    "    assert (len(out) > 0)\n",
    "    features_Xs[tuple(x_val.squeeze().tolist())] = out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.classes.ClassFractionalBiPotential import FractionalBiPotential\n",
    "from configs.RecursiveVPSDE.LSTM_fQuadSinHF.recursive_LSTM_PostMeanScore_fQuadSinHF_T256_H05_tl_110data import get_config as get_config\n",
    "from src.classes.ClassFractionalQuadSin import FractionalQuadSin\n",
    "from configs.RecursiveVPSDE.LSTM_fBiPot.recursive_LSTM_PostMeanScore_fBiPot_T256_H05_tl_110data_SbleTgt import get_config as get_config\n",
    "config = get_config()\n",
    "print(config.data_path)\n",
    "print(config.scoreNet_trained_path)\n",
    "num_paths = 0\n",
    "num_time_steps = config.ts_length\n",
    "isUnitInterval = True\n",
    "diff = 1\n",
    "initial_state = 0.\n",
    "rvs = None\n",
    "H = 0.5\n",
    "deltaT = config.deltaT\n",
    "t0 = config.t0\n",
    "t1 = config.t1\n",
    "if \"QuadSin\" in config.data_path:\n",
    "    fBiPot = FractionalQuadSin(quad_coeff=config.quad_coeff, sin_space_scale=config.sin_space_scale, sin_coeff = config.sin_coeff, diff=diff, X0=initial_state)\n",
    "elif \"BiPot\" in config.data_path:\n",
    "    fBiPot = FractionalBiPotential(quartic_coeff=config.quartic_coeff, quad_coeff=config.quad_coeff, const = config.const, diff=diff, X0=initial_state)\n",
    "if num_paths > 0:\n",
    "    sim_data = np.array(\n",
    "        [fBiPot.euler_simulation(H=H, N=num_time_steps, deltaT=deltaT, isUnitInterval=isUnitInterval, X0=initial_state, Ms=None, gaussRvs=rvs,\n",
    "                               t0=t0, t1=t1) for _ in (range(num_paths))]).reshape((num_paths, num_time_steps+1))\n",
    "\n",
    "    plt.hist(sim_data.flatten(), density=True, bins=150)\n",
    "    print(max(np.abs(sim_data.flatten())))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "diffs = []\n",
    "paths = []\n",
    "for k in range(num_paths):\n",
    "    path = sim_data[k,:]\n",
    "    if \"QuadSin\" in config.data_path:\n",
    "        drifts = -2*config.quad_coeff * path[:-1] + config.sin_space_scale*config.sin_coeff*np.sin(config.sin_space_scale*path[:-1])\n",
    "    elif \"BiPot\" in config.data_path:\n",
    "        drifts = -(4*config.quartic_coeff * np.power(path[:-1],3) + config.quad_coeff*path[:-1] + config.const)\n",
    "    #plt.scatter(path[:-1], drifts[1:]*deltaT, s=1, label=\"True\")\n",
    "    d = (np.diff(path)[np.abs(path[1:])<np.inf])\n",
    "    if len(d) > 0:\n",
    "        diffs.append(d)\n",
    "    paths.append(path)\n",
    "if num_paths > 0 and (\"QuadSin\" in config.data_path):\n",
    "    cs, bins, _ = plt.hist(config.sin_space_scale*np.concatenate(diffs).flatten(), bins=100, density=True, label=\"Histogram\")\n",
    "    print(max(config.sin_space_scale*np.abs(np.concatenate(diffs).flatten())))\n",
    "    plt.vlines(x=1., ymin=0., ymax=max(cs), color=\"orange\", label=\"Frequency Limit\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rmse_ignore_nans(y_true, y_pred):\n",
    "    assert (y_true.shape[0] == y_pred.shape[0])\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)  # Ignore NaNs in both arrays\n",
    "    return np.sqrt(np.mean((y_true[mask] - y_pred[mask]) ** 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalLSTMTSScoreMatching import ConditionalLSTMTSScoreMatching\n",
    "\n",
    "config = get_config()\n",
    "print(config.beta_min)\n",
    "if config.has_cuda:\n",
    "    device = int(os.environ[\"LOCAL_RANK\"])\n",
    "else:\n",
    "    print(\"Using CPU\\n\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "\n",
    "max_diff_steps = config.max_diff_steps\n",
    "sample_eps = config.sample_eps\n",
    "ts_step = 1 / config.ts_length\n",
    "\n",
    "Nepoch = 1440\n",
    "ts_type_num = 1\n",
    "toSave = False\n",
    "# Fix the number of training epochs and training loss objective loss\n",
    "if \"PM\" in config.scoreNet_trained_path:\n",
    "    PM = ConditionalLSTMTSPostMeanScoreMatching(*config.model_parameters).to(device)\n",
    "else:\n",
    "    PM = ConditionalLSTMTSScoreMatching(*config.model_parameters).to(device)\n",
    "PM.load_state_dict(torch.load(config.scoreNet_trained_path + \"_NEp\" + str(Nepoch)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from configs.RecursiveVPSDE.LSTM_fQuadSinHF.recursive_LSTM_PostMeanScore_fQuadSinHF_T256_H05_tl_110data import get_config\n",
    "gconfig = get_config()\n",
    "print(gconfig.loss_factor)\n",
    "with open(gconfig.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = np.array(pickle.load(f))\n",
    "start_idx = 0\n",
    "plt.scatter(np.arange(start_idx, losses.shape[0]), losses[start_idx:],s=2, label=\"Small\")\n",
    "#plt.hlines(np.sqrt(config.deltaT), xmin = start_idx, xmax=losses.shape[0]-start_idx, color=\"red\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "losses[-1]/losses[start_idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from configs.RecursiveVPSDE.LSTM_fBiPot.recursive_LSTM_PostMeanScore_fBiPot_T256_H05_tl_110data_SbleTgt import get_config as get_config\n",
    "gconfig2 = get_config()\n",
    "with open(gconfig2.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        print(f)\n",
    "        losses2 = np.array(pickle.load(f))[:losses.shape[0]]\n",
    "plt.scatter(np.arange(start_idx, losses2.shape[0]), losses2[start_idx:],s=2, label=\"Stable Target\")\n",
    "#plt.hlines(np.sqrt(config.deltaT), xmin = start_idx, xmax=losses.shape[0]-start_idx, color=\"red\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "losses2[-1]/losses2[start_idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_idx = 00\n",
    "def compute_ema(loss_tensor, beta):\n",
    "    ema_values = np.zeros_like(loss_tensor)  # Initialize EMA tensor\n",
    "    ema_values[0] = loss_tensor[0]  # First value stays the same\n",
    "\n",
    "    for i in range(1, len(loss_tensor)):\n",
    "        ema_values[i] = beta * ema_values[i - 1] + (1 - beta) * loss_tensor[i]\n",
    "\n",
    "    return ema_values\n",
    "# Define EMA decay rates\n",
    "beta_short = 0.9   # Short-term trend (reacts quickly)\n",
    "beta_long = 0.99   # Long-term trend (smoother)\n",
    "\n",
    "# Compute EMAs\n",
    "short_term_ema = compute_ema(losses, beta_short)\n",
    "long_term_ema = compute_ema(losses, beta_long)\n",
    "plt.scatter(np.arange(start_idx, short_term_ema.shape[0]), (short_term_ema[start_idx:]),s=2, label=\"Short Term Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.scatter(np.arange(start_idx, long_term_ema.shape[0]), (long_term_ema[start_idx:]),s=2, label=\"Long Term Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ndiff = config.max_diff_steps\n",
    "if \"PMS\" in config.scoreNet_trained_path:\n",
    "    type = \"PMS\"\n",
    "elif \"PM\" in config.scoreNet_trained_path:\n",
    "    type = \"PM\"\n",
    "else:\n",
    "    type = \"\"\n",
    "\n",
    "if \"fSin\" in config.data_path:\n",
    "    file_path = f\"/Users/marcos/GitHubRepos/FractionalBrownianMotion/experiments/results/TS{type}_LSTM_fSin_DriftEvalExp_{Nepoch}Nep_{config.loss_factor}LFactor_10MeanRev_{Ndiff}DiffSteps_\"\n",
    "elif \"fQuadSinHF\" in config.data_path:\n",
    "    file_path = (\n",
    "            project_config.ROOT_DIR + f\"experiments/results/TS{type}_LSTM_fQuadSinHF_DriftEvalExp_{Nepoch}Nep_{config.loss_factor}LFactor_{config.t0}t0_{config.deltaT:.3e}dT_{config.quad_coeff}a_{config.sin_coeff}b_{config.sin_space_scale}c_{config.deltaT:.3e}dT_{config.beta_max:.1e}betaMax_\").replace(\n",
    "        \".\", \"\")\n",
    "    print(file_path)\n",
    "elif \"fBiPotSmall\" in config.data_path:\n",
    "    file_path = (\n",
    "            project_config.ROOT_DIR + f\"experiments/results/TS{type}_LSTM_fBiPotSmall_DriftEvalExp_{Nepoch}Nep_{config.loss_factor}LFactor_{config.quartic_coeff}a_{config.quad_coeff}b_{config.const}c_{config.max_diff_steps}DiffSteps_\").replace(\n",
    "        \".\", \"\")\n",
    "elif \"fBiPot\" in config.data_path:\n",
    "    file_path = (\n",
    "            project_config.ROOT_DIR + f\"experiments/results/TS{type}_LSTM_ST_fBiPot_DriftEvalExp_{Nepoch}Nep_{config.loss_factor}LFactor_{config.t0}t0_{config.deltaT:.3e}dT_{config.quartic_coeff}a_{config.quad_coeff}b_{config.const}c_{config.deltaT:.3e}dT_{config.beta_max:.1e}betaMax_\").replace(\n",
    "        \".\", \"\")\n",
    "muhats = torch.Tensor(np.load(file_path+\"muhats.npy\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xshape = muhats.shape[0]\n",
    "if \"fQuadSinHF\" in config.data_path:\n",
    "    if config.deltaT > 1/(32*256):\n",
    "        Xs = torch.linspace(-1.2, 1.2, steps=Xshape)\n",
    "    else:\n",
    "        Xs = torch.linspace(-.4, .4, steps=Xshape)\n",
    "    ts_type = \"fQuadSinHF\"\n",
    "elif \"fSin\" in config.data_path:\n",
    "    Xs = torch.Tensor(np.linspace(-3,3,Xshape))#np.load(file_path+\"numpyXs.npy\"))\n",
    "    ts_type = \"fSin\"\n",
    "elif \"fBiPotSmall\" in config.data_path:\n",
    "    Xs = torch.Tensor(np.linspace(-1.5,1.5,Xshape))#np.load(file_path+\"numpyXs.npy\"))\n",
    "    ts_type=\"fBiPotSmall\"\n",
    "elif \"fBiPot\" in config.data_path:\n",
    "    Xs = torch.Tensor(np.linspace(-1.5,1.5,Xshape))#np.load(file_path+\"numpyXs.npy\"))\n",
    "    ts_type=\"fBiPot\"\n",
    "if type == \"\":\n",
    "    type=\"Standard\"\n",
    "print(type, ts_type, Ndiff, muhats.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_drift_estimator(mean, stds, numpy_Xs, type, true_drift, ts_type,ts_type_num, Nepoch,toSave:bool = True):\n",
    "    fig, ax = plt.subplots(figsize=(14,9))\n",
    "    rmse = rmse_ignore_nans(true_drift, mean).astype(np.float64)#np.power(np.mean(np.power(true_drift - mean, 2)), 0.5)\n",
    "    ax.scatter(numpy_Xs, true_drift, color=\"red\", label=\"True Drift\")\n",
    "\n",
    "    #ax.errorbar(numpy_Xs, mean, fmt=\"o\",yerr=2*stds, label=\"Estimated Drift\")\n",
    "    plt.scatter(numpy_Xs, mean, label=\"Estimated Drift\", color=\"blue\")\n",
    "    ax.set_title(rf\"RMSE {round(rmse,3)} for LSTM Score Estimator\", fontsize=40)\n",
    "    ax.tick_params(labelsize=38)\n",
    "    ax.set_xlabel(\"State $X$\", fontsize=38)\n",
    "    ax.set_ylabel(\"Drift Value\", fontsize=38)\n",
    "    ax.legend(fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    if toSave:\n",
    "        plt.savefig(f\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModelPresentationImages/{ts_type}{ts_type_num}_{type}_LSTM_{Nepoch}Nep.png\",  bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type,muhats.shape)\n",
    "assert (config.max_diff_steps == 10000)\n",
    "if \"fQuadSin\" in config.data_path:\n",
    "    true_drifts = -2.*config.quad_coeff * Xs.unsqueeze(-1) + config.sin_coeff * config.sin_space_scale*np.sin(config.sin_space_scale*Xs).unsqueeze(-1)\n",
    "    print(config.quad_coeff, config.sin_coeff, config.sin_space_scale)\n",
    "elif \"fSin\" in config.data_path:\n",
    "    true_drifts = config.mean_rev*np.sin(1*Xs).unsqueeze(-1)\n",
    "elif \"BiPot\" in config.data_path:\n",
    "    true_drifts = -(4.*config.quartic_coeff * np.power(Xs, 3) + 2.*config.quad_coeff * Xs + config.const).unsqueeze(-1)\n",
    "    #true_drifts = true_drifts/(1.+config.deltaT*torch.abs(true_drifts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "diff_mses = (true_drifts - muhats.mean(dim=(0,-1)).numpy()).permute(1,0).pow(2).sum(dim=-1) / (muhats.shape[0])\n",
    "diff_rmses = diff_mses.pow(0.5)\n",
    "fig, ax = plt.subplots(figsize=(14, 9))\n",
    "ax.plot(np.linspace(config.sample_eps, config.end_diff_time, muhats.shape[1]), diff_rmses)\n",
    "ax.set_title(r\"Drift RMSE Against Diffusion Time $\\tau_{s}$\", fontsize=40)\n",
    "ax.tick_params(labelsize=38)\n",
    "plt.yscale(\"log\")\n",
    "ax.set_xlabel(r\"Diffusion Time $\\tau_{s}$\", fontsize=48)\n",
    "ax.set_ylabel(r\"RMSE\", fontsize=38)\n",
    "#plt.savefig(f\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModelPresentationImages/{ts_type}_{type}_RMSEs.png\",  bbox_inches='tight')\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mu_hats = muhats[:, -1, :].reshape(muhats.shape[0], muhats.shape[-1]*1).mean(dim=-1).numpy()\n",
    "print(np.mean(mu_hats), np.std(mu_hats))\n",
    "stds = muhats[:, -1, :].reshape(muhats.shape[0], muhats.shape[-1]*1).std(dim=-1).numpy()\n",
    "plot_drift_estimator(mean=mu_hats, stds=stds, numpy_Xs=Xs.numpy(), type=type, toSave=toSave, true_drift=true_drifts.numpy(), ts_type=ts_type, ts_type_num=ts_type_num, Nepoch=Nepoch)\n",
    "print(np.mean(stds))\n",
    "del muhats, mu_hats, stds, true_drifts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
