{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from configs.RecursiveVPSDE.Markovian_4DLorenz.recursive_Markovian_PostMeanScore_4DLorenz_T256_H05_tl_110data import \\\n",
    "    get_config as get_config\n",
    "from configs import project_config\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "\n",
    "Nepoch = 960  # config.max_epochs[0]\n",
    "# Fix the number of training epochs and training loss objective loss\n",
    "score_model = ConditionalMarkovianTSPostMeanScoreMatching(*config.model_parameters).to(device)\n",
    "score_model.load_state_dict(torch.load(config.scoreNet_trained_path + \"_NEp\" + str(Nepoch)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "num_paths = 10\n",
    "t0 = 0.\n",
    "num_time_steps = 256\n",
    "deltaT = 1. / 256\n",
    "t1 = num_time_steps * deltaT\n",
    "initial_state = np.repeat(np.array(config.initState)[np.newaxis, np.newaxis, :], num_paths, axis=0)\n",
    "assert (initial_state.shape == (num_paths, 1, config.ndims))\n",
    "true_states = np.zeros(shape=(num_paths, 1 + num_time_steps, config.ndims))\n",
    "true_states[:, [0], :] = initial_state"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def true_drift(prev, num_paths, config):\n",
    "    assert (prev.shape == (num_paths, config.ndims))\n",
    "    drift_X = np.zeros((num_paths, config.ndims))\n",
    "    for i in range(config.ndims):\n",
    "        drift_X[:,i] = (prev[:, (i + 1) % config.ndims] - prev[:, i - 2]) * prev[:, i - 1] - prev[:,\n",
    "                                                                                           i] + config.forcing_const\n",
    "    return drift_X[:, np.newaxis, :]\n",
    "# Euler-Maruyama Scheme for Tracking Errors\n",
    "for i in range(1, num_time_steps+1):\n",
    "    eps = np.random.randn(num_paths, 1, config.ndims) * np.sqrt(deltaT)\n",
    "    assert (eps.shape == (num_paths, 1, config.ndims))\n",
    "    true_states[:, [i], :] = true_states[:, [i - 1], :] \\\n",
    "                             + true_drift(true_states[:, i - 1, :], num_paths=num_paths, config=config) * deltaT \\\n",
    "                             + eps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def score_error_eval(score_model, diffusion, num_paths, Z_0s, prev, config, device):\n",
    "    num_taus = 50\n",
    "    Ndiff_discretisation = config.max_diff_steps\n",
    "    assert (prev.shape == (num_paths, config.ndims))\n",
    "    vec_Z_0s = torch.stack([Z_0s for _ in range(num_taus)], dim=0).reshape(num_taus*num_paths, 1, config.ndims).to(device)\n",
    "    conditioner = torch.Tensor(prev[:, np.newaxis, :]).to(device) # TODO: Check this is how we condition wheen D>1\n",
    "    vec_conditioner = torch.stack([conditioner for _ in range(num_taus)], dim=0).reshape(num_taus*num_paths, 1, config.ndims).to(device)\n",
    "    vec_Z_taus = diffusion.prior_sampling(shape=(num_taus*num_paths, 1, config.ndims)).to(device)\n",
    "\n",
    "    # We are going to be evaluating the score ONLY at \\tau_{S-1} --> no need for full reverse diffusion!!\n",
    "    # diffusion_times = torch.linspace(config.sample_eps, 1., config.max_diff_steps)\n",
    "    # d = diffusion_times[Ndiff_discretisation - 1].to(device)\n",
    "    # diff_times = torch.Tensor([d]).to(device)\n",
    "    difftime_idx = Ndiff_discretisation - 1\n",
    "    errs = np.zeros((num_paths, Ndiff_discretisation, config.ndims))\n",
    "    while difftime_idx >= 9900:\n",
    "        diff_times = torch.Tensor([1.]).to(device)\n",
    "        eff_times = diffusion.get_eff_times(diff_times).to(device)\n",
    "        vec_diff_times = torch.concat([diff_times for _ in range(num_taus*num_paths)], dim=0).to(device)\n",
    "        vec_eff_times = torch.concat([torch.concat([eff_times.unsqueeze(-1).unsqueeze(-1) for _ in range(num_taus*num_paths)], dim=0) for _ in range(config.ndims)], dim=-1).to(device)\n",
    "        score_model.eval()\n",
    "        with torch.no_grad():\n",
    "            vec_predicted_score = score_model.forward(times=vec_diff_times, eff_times=vec_eff_times, conditioner=vec_conditioner, inputs=vec_Z_taus)\n",
    "        vec_scores, vec_drift, vec_diffParam = diffusion.get_conditional_reverse_diffusion(x=vec_Z_taus,\n",
    "                                                                                    predicted_score=vec_predicted_score,\n",
    "                                                                                           diff_index=torch.Tensor([int(0)]).to(device),\n",
    "                                                                                    max_diff_steps=Ndiff_discretisation)\n",
    "        vec_scores = vec_scores.reshape((num_taus, num_paths, 1, config.ndims)).permute((1,0,2,3))\n",
    "        assert (vec_scores.shape == (num_paths, num_taus, 1, config.ndims))\n",
    "\n",
    "        beta_taus = torch.exp(-0.5 * eff_times).to(device)\n",
    "        sigma_taus = torch.pow(1. - torch.pow(beta_taus, 2), 0.5).to(device)\n",
    "        exp_upper_score = -(vec_Z_taus - beta_taus*vec_Z_0s) / sigma_taus\n",
    "        exp_upper_score = exp_upper_score.reshape((num_taus, num_paths, 1, config.ndims)).permute((1,0,2,3))\n",
    "        assert (exp_upper_score.shape == (num_paths, num_taus, 1, config.ndims))\n",
    "\n",
    "        errs[:,[difftime_idx], :] = torch.mean(torch.pow(vec_scores-exp_upper_score,2), dim=1)\n",
    "        vec_z = torch.randn_like(vec_drift).to(device)\n",
    "        vec_Z_taus = vec_drift + vec_diffParam * vec_z\n",
    "    return errs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [50:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((num_paths, \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m+\u001B[39m num_time_steps, config\u001B[38;5;241m.\u001B[39mmax_diff_steps, config\u001B[38;5;241m.\u001B[39mndims))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_time_steps\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m----> 4\u001B[0m     erri \u001B[38;5;241m=\u001B[39m \u001B[43mscore_error_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscore_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscore_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiffusion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiffusion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_paths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_paths\u001B[49m\u001B[43m,\u001B[49m\u001B[43mZ_0s\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrue_states\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprev\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_states\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     errors[:, i, :, :] \u001B[38;5;241m=\u001B[39m erri\n",
      "Cell \u001B[0;32mIn[41], line 23\u001B[0m, in \u001B[0;36mscore_error_eval\u001B[0;34m(score_model, diffusion, num_paths, Z_0s, prev, config, device)\u001B[0m\n\u001B[1;32m     21\u001B[0m score_model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 23\u001B[0m     vec_predicted_score \u001B[38;5;241m=\u001B[39m \u001B[43mscore_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_diff_times\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meff_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_eff_times\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconditioner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_conditioner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_Z_taus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m vec_scores, vec_drift, vec_diffParam \u001B[38;5;241m=\u001B[39m diffusion\u001B[38;5;241m.\u001B[39mget_conditional_reverse_diffusion(x\u001B[38;5;241m=\u001B[39mvec_Z_taus,\n\u001B[1;32m     25\u001B[0m                                                                             predicted_score\u001B[38;5;241m=\u001B[39mvec_predicted_score,\n\u001B[1;32m     26\u001B[0m                                                                                    diff_index\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mTensor([\u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0\u001B[39m)])\u001B[38;5;241m.\u001B[39mto(device),\n\u001B[1;32m     27\u001B[0m                                                                             max_diff_steps\u001B[38;5;241m=\u001B[39mNdiff_discretisation)\n\u001B[1;32m     28\u001B[0m vec_scores \u001B[38;5;241m=\u001B[39m vec_scores\u001B[38;5;241m.\u001B[39mreshape((num_taus, num_paths, \u001B[38;5;241m1\u001B[39m, config\u001B[38;5;241m.\u001B[39mndims))\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m))\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/models/TimeDependentScoreNetworks/ClassConditionalMarkovianTSPostMeanScoreMatching.py:174\u001B[0m, in \u001B[0;36mConditionalMarkovianTSPostMeanScoreMatching.forward\u001B[0;34m(self, inputs, times, conditioner, eff_times)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cond_up\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    173\u001B[0m     cond_up \u001B[38;5;241m=\u001B[39m cond_up\u001B[38;5;241m.\u001B[39mreshape(cond_up\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39mcond_up\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 174\u001B[0m x, skip_connection \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconditioner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcond_up\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdiffusion_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiffusion_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mleaky_relu(x, \u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m    176\u001B[0m skip\u001B[38;5;241m.\u001B[39mappend(skip_connection)\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/models/TimeDependentScoreNetworks/ClassConditionalMarkovianTSPostMeanScoreMatching.py:93\u001B[0m, in \u001B[0;36mResidualBlock.forward\u001B[0;34m(self, x, conditioner, diffusion_step)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, conditioner, diffusion_step):\n\u001B[1;32m     92\u001B[0m     diffusion_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiffusion_projection(diffusion_step)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 93\u001B[0m     conditioner \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconditioner_projection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconditioner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m     y \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m diffusion_step\n\u001B[1;32m     95\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilated_conv(y) \u001B[38;5;241m+\u001B[39m conditioner\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    307\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    308\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "errors = np.zeros((num_paths, 1 + num_time_steps, config.max_diff_steps, config.ndims))\n",
    "for i in tqdm(range(1, num_time_steps+1)):\n",
    "    erri = score_error_eval(score_model=score_model, diffusion=diffusion, num_paths=num_paths,Z_0s=torch.Tensor(true_states[:, [i],:]).to(device), prev=true_states[:, i-1,:], config=config, device=device)\n",
    "    errors[:, i, :, :] = erri"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
