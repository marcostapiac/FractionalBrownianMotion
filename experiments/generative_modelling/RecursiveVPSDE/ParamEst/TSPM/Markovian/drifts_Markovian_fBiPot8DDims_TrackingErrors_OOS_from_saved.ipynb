{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from configs import project_config\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims.recursive_Markovian_PostMeanScore_fBiPot8Dims_T256_H05_tl_110data_StbleTgt  import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rmse_ignore_nans(y_true, y_pred):\n",
    "    return np.nanmean((y_true-y_pred)**2)\n",
    "\n",
    "def plot_ewma_losses(epochs, losses):\n",
    "    start_idx = 00\n",
    "    def compute_ema(loss_tensor, beta):\n",
    "        ema_values = np.zeros_like(loss_tensor)  # Initialize EMA tensor\n",
    "        ema_values[0] = loss_tensor[0]  # First value stays the same\n",
    "\n",
    "        for i in range(1, len(loss_tensor)):\n",
    "            ema_values[i] = beta * ema_values[i - 1] + (1 - beta) * loss_tensor[i]\n",
    "\n",
    "        return ema_values\n",
    "    # Define EMA decay rates\n",
    "    beta_short = 0.9   # Short-term trend (reacts quickly)\n",
    "    beta_long = 0.99   # Long-term trend (smoother)\n",
    "\n",
    "    # Compute EMAs\n",
    "    short_term_ema = compute_ema(losses, beta_short)\n",
    "    long_term_ema = compute_ema(losses, beta_long)\n",
    "    plt.scatter(epochs[start_idx:], (short_term_ema[start_idx:]),s=2, label=\"Short Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.scatter(epochs[start_idx:], (long_term_ema[start_idx:]),s=2, label=\"Long Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_drift_estimator(mean, mean_min, mean_max, numpy_Xs, true_drift, Nepoch ,toSave: bool = False):\n",
    "    rmse = rmse_ignore_nans(true_drift, mean).astype(\n",
    "        np.float64)  #np.power(np.mean(np.power(true_drift - mean, 2)), 0.5)\n",
    "        # Create a 4x2 grid of subplots\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(20, 24))\n",
    "    axes = axes.flatten()  # Flatten to easily index with a single loop\n",
    "    for d in range(mean.shape[-1]):\n",
    "        axes[d].scatter(numpy_Xs[:, d], true_drift[:, d], color=\"red\", label=\"True Drift\")\n",
    "        ymin = mean[:, d] - mean_min[:, d]\n",
    "        ymax = mean_max[:, d] - mean[:, d]\n",
    "        ymin[ymin < 0.] = 0.\n",
    "        ymax[ymax < 0.] = 0.\n",
    "        axes[d].errorbar(numpy_Xs[:, d], mean[:, d], yerr=[ymin, ymax], xerr=None, fmt='o', color=\"blue\", alpha=0.4)\n",
    "        axes[d].errorbar(numpy_Xs[:, d], mean[:, d], label=\"Estimated Drift\", color=\"blue\")\n",
    "        axes[d].set_title(rf\"Score Estimator for $\\mu_4$\", fontsize=22)\n",
    "        axes[d].tick_params(labelsize=13)\n",
    "        axes[d].set_xlabel(f\"State $Y$ at Dimension {d+1}\", fontsize=20)\n",
    "        axes[d].set_ylabel(\"Drift Value\", fontsize=20)\n",
    "        axes[d].legend(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    if toSave:\n",
    "        plt.savefig((root_dir +f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDims/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDims_DriftEvalExp_{Nepoch}Nep_{config.loss_factor}LFac\").replace(\n",
    "                \".\", \"\") + \".png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "deltaT = config.deltaT\n",
    "root_dir =\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/\"\n",
    "print(config.loss_factor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = (np.array(pickle.load(f)).astype(float))\n",
    "Nepochs_losses = np.arange(losses.shape[0])\n",
    "plt.scatter(Nepochs_losses,  losses, s=10)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "Nepochs_losses[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ewma_losses(epochs=Nepochs_losses, losses=losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss_LR\", 'rb') as f:\n",
    "        LRs = (np.array(pickle.load(f)).astype(float))\n",
    "start = 0#935\n",
    "end = -1#935+152\n",
    "plt.scatter(Nepochs_losses[start:end],  LRs[start:end], s=10, label=\"Learning Rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(LRs[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_drift_files(config, ts_type):\n",
    "    root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/8DDims/\"\n",
    "    driftoostrack_true_files = []\n",
    "    driftoostrack_local_files = []\n",
    "    for file in os.listdir(root_score_dir):\n",
    "        if \"_MLP_\" in file and ts_type in file:\n",
    "            if \"DriftTrack\" in file and \"true\" in file:\n",
    "                driftoostrack_true_files.append(root_score_dir+file)\n",
    "            elif \"DriftTrack\" in file and \"global\" in file:\n",
    "                driftoostrack_local_files.append(root_score_dir+file)\n",
    "    assert len(driftoostrack_true_files)>0, \"No oos drift track files found\"\n",
    "    assert len(driftoostrack_local_files)>0, \"No oos drift track files found\"\n",
    "    assert(len(driftoostrack_true_files) == len(driftoostrack_true_files))\n",
    "    def extract_bw_drift_track_number(s):\n",
    "        match = s.split(\"Nep_\")[0].split(\"_\")[-1]\n",
    "        return int(match)\n",
    "    driftoostrack_true_files = sorted(driftoostrack_true_files, key=extract_bw_drift_track_number)\n",
    "    driftoostrack_local_files = sorted(driftoostrack_local_files, key=extract_bw_drift_track_number)\n",
    "    Nepochs_track = [extract_bw_drift_track_number(f) for f in driftoostrack_true_files]\n",
    "    return driftoostrack_true_files, driftoostrack_local_files, Nepochs_track"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts_type = f\"ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDims\".replace(\".\", \"\")\n",
    "drift_true_files, drift_local_files, Nepochs_track = get_drift_files(config=config, ts_type=ts_type)\n",
    "len(Nepochs_track)\n",
    "print(drift_true_files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_evalexp_drift_files(ts_type_str):\n",
    "    root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/8DDims/\"\n",
    "    driftevalexp_files = []\n",
    "    for file in os.listdir(root_score_dir):\n",
    "        if \"_MLP_\" in file:\n",
    "            if ((\"ST\" in ts_type_str and \"_ST_\" in file) or ((\"ST\" not in ts_type_str and \"_ST_\" not in file))):\n",
    "                if \"muhats\" in file and \"DriftEvalExp\" in file:\n",
    "                    driftevalexp_files.append(root_score_dir+file)\n",
    "    assert len(driftevalexp_files)>0, \"No eval exp files found\"\n",
    "    def extract_Nepoch_drift_eval_exp_number(s):\n",
    "        match = s.split(\"Nep_\")[0].split(\"_\")[-1]\n",
    "        return int(match)\n",
    "    driftevalexp_files = sorted(driftevalexp_files, key=extract_Nepoch_drift_eval_exp_number)\n",
    "    Nepochs_drifteval = [extract_Nepoch_drift_eval_exp_number(f) for f in driftevalexp_files]\n",
    "    return driftevalexp_files, Nepochs_drifteval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "driftevalexp_files, Nepochs_drifteval = get_evalexp_drift_files(ts_type_str=ts_type)\n",
    "len(Nepochs_track)\n",
    "print(drift_true_files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drift_track_rmses = {}\n",
    "epochs_iter = Nepochs_track\n",
    "Nepochs_keep = []\n",
    "for Nepoch, true, local in zip(*[epochs_iter, drift_true_files, drift_local_files]):\n",
    "    try:\n",
    "        print(str(Nepoch), str(Nepoch)[-1])\n",
    "        all_true_states = np.load(true)\n",
    "        all_local_states= np.load(local)\n",
    "        time_steps = np.linspace(config.t0,config.deltaT*all_true_states.shape[2],all_true_states.shape[2])\n",
    "        all_global_errors = np.sum(np.power(all_true_states- all_local_states,2), axis=-1)\n",
    "        all_global_errors=all_global_errors.reshape(-1, all_global_errors.shape[-1])            # (K, N, T)\n",
    "        total_local_errors = np.sqrt(np.mean(all_global_errors, axis=(0)))/np.sqrt(time_steps)\n",
    "        all_paths_err = np.sqrt(all_global_errors)/np.sqrt(time_steps)\n",
    "        total_local_errors[total_local_errors==np.inf] = 0.\n",
    "        all_paths_err[all_paths_err==np.inf] = 0.\n",
    "        drift_track_rmses.update({Nepoch:total_local_errors[-1]})\n",
    "        Nepochs_keep.append(Nepoch)\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        #del all_true_states, all_local_states, all_local_errors, total_local_errors\n",
    "        continue\n",
    "Nepochs_track = Nepochs_keep\n",
    "drift_track_rmses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_exp_rmses = {}\n",
    "for f in zip(*[Nepochs_drifteval, driftevalexp_files]):\n",
    "    Nepoch = f[0]\n",
    "    file = f[1]\n",
    "    try:\n",
    "        muhats = torch.Tensor(np.load(file, allow_pickle=True)).numpy()\n",
    "        Xshape = muhats.shape[0]\n",
    "        Xs = np.concatenate([np.linspace(-4.9, 4.9, num=Xshape).reshape(-1, 1), np.linspace(-4.4, 4.4, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-4.05, 4.05, num=Xshape).reshape(-1,1), np.linspace(-3.9, 3.9, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-3.7, 3.7, num=Xshape).reshape(-1,1), np.linspace(-3.6, 3.6, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-3.5, 3.5, num=Xshape).reshape(-1,1), np.linspace(-3.4, 3.4, num=Xshape).reshape(-1,1)],\n",
    "                                    axis=1)\n",
    "        true_drifts = -(4. * np.array(config.quartic_coeff) * np.power(Xs,\n",
    "                                                                       3) + 2. * np.array(\n",
    "                config.quad_coeff) * Xs + np.array(config.const))\n",
    "        mu_hats = muhats[:, -1, :, :].reshape(muhats.shape[0], muhats.shape[2],muhats.shape[-1]*1).mean(axis=1)\n",
    "        mse = np.nanmean(np.sum((true_drifts-mu_hats)**2, axis=-1))\n",
    "        eval_exp_rmses.update({Nepoch: round(mse, 6)})\n",
    "    except pickle.UnpicklingError as e:\n",
    "        continue\n",
    "    except FileNotFoundError as e:\n",
    "        continue\n",
    "Nepochs_drifteval = np.array(list(eval_exp_rmses.keys())).flatten()\n",
    "eval_exp_rmses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = np.array(pickle.load(f)).astype(float)\n",
    "Nepochs_losses = np.arange(losses.shape[0])\n",
    "print(Nepochs_losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "common_epochs = np.intersect1d(Nepochs_losses, Nepochs_track)\n",
    "print(Nepochs_losses)\n",
    "common_epochs = np.intersect1d(common_epochs, np.arange(10, 3500))\n",
    "start_idx = 0\n",
    "common_epochs = common_epochs[start_idx:]\n",
    "losses_idx = [np.argwhere(c == Nepochs_losses)[0,0] for c in common_epochs]\n",
    "track_idx = [np.argwhere(c == Nepochs_track)[0,0] for c in common_epochs]\n",
    "red_losses = losses[losses_idx]\n",
    "track_rmses = np.array(list(drift_track_rmses.values()))[track_idx]\n",
    "print(common_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "common_epochs = np.intersect1d(np.intersect1d(Nepochs_losses, Nepochs_drifteval), Nepochs_track)\n",
    "start_idx = 0\n",
    "common_epochs = common_epochs[start_idx:]\n",
    "losses_idx = [np.argwhere(c == Nepochs_losses)[0,0] for c in common_epochs]\n",
    "evalexp_idx = [np.argwhere(c == Nepochs_drifteval)[0,0] for c in common_epochs]\n",
    "red_losses = losses[losses_idx]\n",
    "eval_rmses = np.array(list(eval_exp_rmses.values()))[evalexp_idx]\n",
    "track_idx = [np.argwhere(c == Nepochs_track)[0,0] for c in common_epochs]\n",
    "track_rmses = np.array(list(drift_track_rmses.values()))[track_idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "toSave = True\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "sc1 = ax.scatter(common_epochs, red_losses, s=10, label=\"Training Loss\")\n",
    "ax2 = ax.twinx()\n",
    "sc2 = ax2.scatter(common_epochs, eval_rmses, s=20, color=\"orange\",label=\"Domain MSE\")\n",
    "ax.set_xlabel(\"Training Epochs\", fontsize=38)\n",
    "ax.set_title(r\"Losses for $\\mu_{4}$\", fontsize=40)\n",
    "ax.tick_params(axis=\"both\",labelsize=24)\n",
    "ax2.tick_params(axis=\"both\",labelsize=24)\n",
    "plt.tight_layout()\n",
    "handles = [sc1, sc2]\n",
    "labels = [h.get_label() for h in handles]\n",
    "# Add a single legend on ax1\n",
    "ax.legend(handles, labels, fontsize=24)\n",
    "if toSave:\n",
    "    plt.savefig((root_dir + f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDims/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDims_LossesEvalExp_{config.loss_factor}LFac\").replace(\".\",\"\")+\".png\",  bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "sc1 = ax.scatter(common_epochs, red_losses, s=10, label=\"Training Loss\")\n",
    "ax2 = ax.twinx()\n",
    "sc2 = ax2.scatter(common_epochs, track_rmses, s=20, color=\"red\",label=\"Tracking MSE\")\n",
    "ax.set_xlabel(\"Training Epochs\", fontsize=38)\n",
    "ax.set_title(r\"Losses for $\\mu_{4}$\", fontsize=40)\n",
    "ax.tick_params(axis=\"both\",labelsize=24)\n",
    "ax2.tick_params(axis=\"both\",labelsize=24)\n",
    "#ax.set_yscale(\"log\")\n",
    "#ax2.set_yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "handles = [sc1, sc2]\n",
    "labels = [h.get_label() for h in handles]\n",
    "# Add a single legend on ax1\n",
    "ax.legend(handles, labels, fontsize=24)\n",
    "if toSave:\n",
    "    plt.savefig((root_dir + f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDims/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDims_LossesTrack_{config.loss_factor}LFac\").replace(\".\",\"\")+\".png\",  bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%skip\n",
    "curr_best_mse = np.inf\n",
    "toSave = True\n",
    "for f_idx in range(len(common_epochs)):\n",
    "    Nepoch = common_epochs[f_idx]\n",
    "    try:\n",
    "        if Nepoch < 10: raise FileNotFoundError\n",
    "        ff_idx = np.argwhere(Nepoch == np.array(epochs_iter))[0,0]\n",
    "        file = driftevalexp_files[ff_idx]\n",
    "        muhats = torch.Tensor(np.load(file, allow_pickle=True)).numpy()\n",
    "        Xshape = muhats.shape[0]\n",
    "        Xs = np.concatenate([np.linspace(-4.9, 4.9, num=Xshape).reshape(-1, 1), np.linspace(-4.4, 4.4, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-4.05, 4.05, num=Xshape).reshape(-1,1), np.linspace(-3.9, 3.9, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-3.7, 3.7, num=Xshape).reshape(-1,1), np.linspace(-3.6, 3.6, num=Xshape).reshape(-1,1), \\\n",
    "                                     np.linspace(-3.5, 3.5, num=Xshape).reshape(-1,1), np.linspace(-3.4, 3.4, num=Xshape).reshape(-1,1)],\n",
    "                                    axis=1)\n",
    "        true_drifts = -(4. * np.array(config.quartic_coeff) * np.power(Xs,\n",
    "                                                                       3) + 2. * np.array(\n",
    "                config.quad_coeff) * Xs + np.array(config.const))\n",
    "        true_drifts = true_drifts/(1.+config.deltaT*np.abs(true_drifts))\n",
    "\n",
    "        muhats = muhats[:, -1, :, :].reshape(muhats.shape[0], muhats.shape[2],muhats.shape[-1]*1)\n",
    "        mu_hats = muhats.mean(axis=1)\n",
    "        print(mu_hats.shape, true_drifts.shape)\n",
    "        mse = np.nanmean(np.sum((true_drifts-mu_hats)**2, axis=-1))\n",
    "        if mse < curr_best_mse:\n",
    "            mu_hats_minq = np.quantile(muhats, q=0.005, axis=1) # Lower bound\n",
    "            mu_hats_maxq = np.quantile(muhats, q=0.995, axis=1) # uPPER bound\n",
    "            plot_drift_estimator(mean=mu_hats, mean_min=mu_hats_minq, mean_max=mu_hats_maxq, numpy_Xs=Xs, true_drift=true_drifts, Nepoch=Nepoch, toSave=toSave)\n",
    "            curr_best_mse = mse\n",
    "            print(f\"MSE  {curr_best_mse} at Nepoch {Nepoch}\\n\")\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr_rmse = np.inf\n",
    "toSave = True\n",
    "for f_idx in range(len(common_epochs)):\n",
    "    Nepoch = common_epochs[f_idx]\n",
    "    ff_idx = np.argwhere(Nepoch == np.array(epochs_iter))[0,0]\n",
    "    true = drift_true_files[ff_idx]\n",
    "    local = drift_local_files[ff_idx]\n",
    "    try:\n",
    "        if Nepoch < 10: raise FileNotFoundError\n",
    "        num_diff_times = 1\n",
    "        all_true_states = np.load(true)\n",
    "        all_local_states= np.load(local)\n",
    "        print(all_local_states.shape)\n",
    "        time_steps = np.linspace(config.t0,config.deltaT*all_true_states.shape[2],all_true_states.shape[2])\n",
    "        all_global_errors = np.sum(np.power(all_true_states- all_local_states,2), axis=-1)\n",
    "        all_global_errors=all_global_errors.reshape(-1, all_global_errors.shape[-1])            # (K, N, T)\n",
    "        total_local_errors = np.sqrt(np.mean(all_global_errors, axis=(0)))/np.sqrt(time_steps)\n",
    "        all_paths_err = np.sqrt(all_global_errors)/np.sqrt(time_steps)\n",
    "        total_local_errors[total_local_errors==np.inf] = 0.\n",
    "        all_paths_err[all_paths_err==np.inf] = 0.\n",
    "        total_local_errors_minq, total_local_errors_maxq  = np.quantile(all_paths_err, q=[0.005, 0.995], axis=0) # (T,)<\n",
    "        if total_local_errors[-1] < curr_rmse:\n",
    "            curr_rmse = total_local_errors[-1]\n",
    "            fig, ax = plt.subplots(figsize=(14,9))\n",
    "            plt.grid(True)\n",
    "            ax.scatter(time_steps, total_local_errors)\n",
    "            plt.fill_between(time_steps,y1=total_local_errors_minq, y2=total_local_errors_maxq, color=\"blue\", alpha=0.4)\n",
    "            ax.set_title(rf\"Pathwise RMSE for Score Estimator for $\\mu_4$\",fontsize=40)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=38)\n",
    "            ax.set_xlabel(\"Time Axis\", fontsize=38)\n",
    "            ax.tick_params(labelsize=38)\n",
    "            plt.tight_layout()\n",
    "            if toSave:\n",
    "                plt.savefig((root_dir + f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDims/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDims_DriftTrack_{Nepoch}Nep_{round(total_local_errors_minq[-1], 8)}_MinIQR_{round(total_local_errors[-1], 8)}MeanIQR_{round(total_local_errors_maxq[-1], 8)}_MaxIQR\").replace(\".\", \"\")+\".png\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(f\"Final time cumulative MSE local-time error {total_local_errors[-1]} with final IQR {(total_local_errors_minq[-1], total_local_errors_maxq[-1])} at Nepoch {Nepoch}\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
