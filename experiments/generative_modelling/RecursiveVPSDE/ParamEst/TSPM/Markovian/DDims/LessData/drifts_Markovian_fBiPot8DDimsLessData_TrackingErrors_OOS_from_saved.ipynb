{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from configs import project_config\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims.recursive_Markovian_PostMeanScore_fBiPot8Dims_T256_H05_tl_110data_StbleTgt  import get_config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rmse_ignore_nans(y_true, y_pred):\n",
    "    return np.nanmean((y_true-y_pred)**2)\n",
    "\n",
    "def plot_ewma_losses(epochs, losses):\n",
    "    start_idx = 00\n",
    "    def compute_ema(loss_tensor, beta):\n",
    "        ema_values = np.zeros_like(loss_tensor)  # Initialize EMA tensor\n",
    "        ema_values[0] = loss_tensor[0]  # First value stays the same\n",
    "\n",
    "        for i in range(1, len(loss_tensor)):\n",
    "            ema_values[i] = beta * ema_values[i - 1] + (1 - beta) * loss_tensor[i]\n",
    "\n",
    "        return ema_values\n",
    "    # Define EMA decay rates\n",
    "    beta_short = 0.9   # Short-term trend (reacts quickly)\n",
    "    beta_long = 0.99   # Long-term trend (smoother)\n",
    "\n",
    "    # Compute EMAs\n",
    "    short_term_ema = compute_ema(losses, beta_short)\n",
    "    long_term_ema = compute_ema(losses, beta_long)\n",
    "    plt.scatter(epochs[start_idx:], (short_term_ema[start_idx:]),s=2, label=\"Short Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.scatter(epochs[start_idx:], (long_term_ema[start_idx:]),s=2, label=\"Long Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "deltaT = config.deltaT\n",
    "assert config.feat_thresh == 1.\n",
    "root_dir =\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/\"\n",
    "print(config.loss_factor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = (np.array(pickle.load(f)).astype(float))\n",
    "Nepochs_losses = np.arange(losses.shape[0])\n",
    "plt.scatter(Nepochs_losses,  losses, s=10)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "Nepochs_losses[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ewma_losses(epochs=Nepochs_losses, losses=losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss_LR\", 'rb') as f:\n",
    "        LRs = (np.array(pickle.load(f)).astype(float))\n",
    "start = 0#935\n",
    "end = -1#935+152\n",
    "plt.scatter(Nepochs_losses[start:end],  LRs[start:end], s=10, label=\"Learning Rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(LRs[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = np.array(pickle.load(f)).astype(float)\n",
    "Nepochs_losses = np.arange(losses.shape[0])\n",
    "print(Nepochs_losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/8DDimsLessData/\"\n",
    "mses=[]\n",
    "for file in os.listdir(root_score_dir):\n",
    "    if \"MSE\" in file:\n",
    "        mses.append(pd.read_parquet(root_score_dir+file, engine=\"fastparquet\"))\n",
    "mses = pd.concat(mses).reset_index(drop=False).rename({\"index\":\"epoch\"}, axis=1).sort_values(\"epoch\").reset_index(drop=True)\n",
    "Nepochs_track = mses[\"epoch\"].values.flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "common_epochs = np.intersect1d(Nepochs_losses, Nepochs_track)\n",
    "common_epochs = np.intersect1d(common_epochs, np.arange(100, 8000))\n",
    "start_idx = 0\n",
    "common_epochs = common_epochs[start_idx:]\n",
    "losses_idx = np.unique([np.argwhere(c == Nepochs_losses)[0,0] for c in common_epochs])\n",
    "track_idx = np.unique([np.argwhere(c == Nepochs_track)[0,0] for c in common_epochs])\n",
    "red_losses = losses[losses_idx]\n",
    "print(track_idx.shape, common_epochs.shape)\n",
    "#track_rmses = np.array(list(drift_track_rmses.values()))[track_idx]\n",
    "track_rmses = mses.iloc[track_idx,:].mse.values.flatten()\n",
    "print(track_rmses.shape, common_epochs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "toSave = False\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "max_idx = np.argwhere(common_epochs <=40000).flatten()[-1]\n",
    "sc1 = ax.scatter(common_epochs[:max_idx+1], red_losses[:max_idx+1], s=50, label=\"Training Loss\")\n",
    "ax2 = ax.twinx()\n",
    "sc2 = ax2.scatter(common_epochs[:max_idx+1], track_rmses[:max_idx+1], s=50, color=\"red\",label=\"$E^{(\\mu)}_{256}$\")\n",
    "ax.set_xlabel(\"Training Epochs\", fontsize=38)\n",
    "ax.set_title(r\"Losses for $\\mu_{4}$ with $D=8, c=20$\", fontsize=40)\n",
    "ax.tick_params(axis=\"both\",labelsize=38)\n",
    "ax2.tick_params(axis=\"both\",labelsize=38)\n",
    "plt.tight_layout()\n",
    "handles = [sc1, sc2]\n",
    "labels = [h.get_label() for h in handles]\n",
    "# Add a single legend on ax1\n",
    "ax.legend(handles, labels, fontsize=30, markerscale=2)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(mses.iloc[np.argmin(mses.mse), 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "toSave = True\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "max_idx = np.argwhere(common_epochs <=3000).flatten()[-1]\n",
    "sc1 = ax.scatter(common_epochs[:max_idx+1], red_losses[:max_idx+1], s=50, label=\"Training Loss\")\n",
    "ax2 = ax.twinx()\n",
    "sc2 = ax2.scatter(common_epochs[:max_idx+1], track_rmses[:max_idx+1], s=50, color=\"red\",label=\"Time-normalised RMSE\")\n",
    "ax.set_xlabel(\"Training Epochs\", fontsize=38)\n",
    "ax.set_title(r\"Losses for $\\mu_{4}$ with $D=8, c=20$\", fontsize=40)\n",
    "ax.tick_params(axis=\"both\",labelsize=38)\n",
    "ax2.tick_params(axis=\"both\",labelsize=38)\n",
    "plt.tight_layout()\n",
    "handles = [sc1, sc2]\n",
    "labels = [h.get_label() for h in handles]\n",
    "# Add a single legend on ax1\n",
    "ax.legend(handles, labels, fontsize=30, markerscale=2)\n",
    "if toSave:\n",
    "    plt.savefig((root_dir + f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDimsNSLessData/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDimsNS_LossesTrack_{config.loss_factor}LFac\").replace(\".\",\"\")+\".png\",  bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr_rmse = np.inf\n",
    "toSave = True\n",
    "for f_idx in range(len(common_epochs)):\n",
    "    Nepoch = common_epochs[f_idx]\n",
    "    ff_idx = np.argwhere(Nepoch == np.array(epochs_iter))[0,0]\n",
    "    true = drift_true_files[ff_idx]\n",
    "    local = drift_local_files[ff_idx]\n",
    "    try:\n",
    "        if Nepoch < 5: raise FileNotFoundError\n",
    "        num_diff_times = 1\n",
    "        all_true_states = np.load(true)\n",
    "        all_local_states= np.load(local)\n",
    "        print(all_local_states.shape)\n",
    "        time_steps = np.linspace(config.t0,config.deltaT*all_true_states.shape[2],all_true_states.shape[2])\n",
    "        all_global_errors = np.sum(np.power(all_true_states- all_local_states,2), axis=-1)\n",
    "        all_global_errors=all_global_errors.reshape(-1, all_global_errors.shape[-1])            # (K, N, T)\n",
    "        total_local_errors = np.sqrt(np.mean(all_global_errors, axis=(0)))/np.sqrt(time_steps)\n",
    "        all_paths_err = np.sqrt(all_global_errors)/np.sqrt(time_steps)\n",
    "        total_local_errors[total_local_errors==np.inf] = 0.\n",
    "        all_paths_err[all_paths_err==np.inf] = 0.\n",
    "        total_local_errors_minq, total_local_errors_maxq  = np.quantile(all_paths_err, q=[0.005, 0.995], axis=0) # (T,)<\n",
    "        if total_local_errors[-1] < curr_rmse:\n",
    "            curr_rmse = total_local_errors[-1]\n",
    "            fig, ax = plt.subplots(figsize=(14,9))\n",
    "            plt.grid(True)\n",
    "            ax.scatter(time_steps, total_local_errors)\n",
    "            plt.fill_between(time_steps,y1=total_local_errors_minq, y2=total_local_errors_maxq, color=\"blue\", alpha=0.4)\n",
    "            ax.set_title(rf\"Pathwise RMSE for Score Estimator $\\mu_4$\",fontsize=40)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=38)\n",
    "            ax.set_xlabel(\"Time Axis\", fontsize=38)\n",
    "            ax.tick_params(labelsize=38)\n",
    "            plt.tight_layout()\n",
    "            if toSave:\n",
    "                plt.savefig((root_dir + f\"DiffusionModelPresentationImages/TSPM_Markovian/8DDimsNSLessData/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_fBiPot_{config.ndims}DDimsNS_DriftTrack_{Nepoch}Nep_{round(total_local_errors_minq[-1], 8)}_MinIQR_{round(total_local_errors[-1], 8)}MeanIQR_{round(total_local_errors_maxq[-1], 8)}_MaxIQR\").replace(\".\", \"\")+\".png\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(f\"Final time cumulative MSE local-time error {total_local_errors[-1]} with final IQR {(total_local_errors_minq[-1], total_local_errors_maxq[-1])} at Nepoch {Nepoch}\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.resource_logger import wallclock_and_system_metrics\n",
    "data = wallclock_and_system_metrics(config.resource_logging_path, inclusive=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "24.019614780590+2.427880978"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
