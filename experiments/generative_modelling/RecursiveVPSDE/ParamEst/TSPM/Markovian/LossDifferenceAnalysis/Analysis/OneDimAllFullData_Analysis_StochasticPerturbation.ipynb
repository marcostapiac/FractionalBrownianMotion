{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "# Data parameters\n",
    "from tqdm import tqdm\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims.recursive_Markovian_PostMeanScore_fBiPot8Dims_T256_H05_tl_110data_StbleTgt_FULLDATA import get_config\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n",
    "from utils.drift_evaluation_functions import multivar_score_based_MLP_drift_OOS\n",
    "import os\n",
    "import torch\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "time_ax = np.linspace(0, 1/256*(256),257)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "type = \"score\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "save_path = \"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/ExperimentResults/QuadSinHF_NewLongerDriftEvalExp_MSEs_10240NPaths\"\n",
    "normalnoise_score_drifts = np.load(save_path + f\"_score_drifts.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_hermite_drifts = np.load(save_path + f\"_hermite_drifts.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_true_drifts = np.load(save_path + \"_true_drifts.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_score_paths = np.load(save_path + f\"_score_paths.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_hermite_paths = np.load(save_path + f\"_hermite_paths.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_true_paths = np.load(save_path + \"_true_paths.npy\", allow_pickle=True)[:, :257, 0]\n",
    "normalnoise_score_diffs = normalnoise_true_paths-normalnoise_score_paths\n",
    "idxs = np.argsort(np.abs(normalnoise_score_diffs)[:, -1], axis=0).flatten()\n",
    "\n",
    "normalnoise_true_drifts = normalnoise_true_drifts[idxs, :][::-1, :]/256\n",
    "normalnoise_score_drifts = normalnoise_score_drifts[idxs, :][::-1,:]/256\n",
    "normalnoise_hermite_drifts = normalnoise_hermite_drifts[idxs, :][::-1,:]/256\n",
    "\n",
    "normalnoise_true_paths = normalnoise_true_paths[idxs, :][::-1, :]\n",
    "normalnoise_score_paths = normalnoise_score_paths[idxs, :][::-1,:]\n",
    "normalnoise_hermite_paths = normalnoise_hermite_paths[idxs, :][::-1,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marcos/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/trained_models/trained_rec_ST_0010FTh_PM_MLP_2LFac_NSTgtNFMReg_fBiPot_8DDims_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110 40000\n",
      "trained_rec_ST_0010FTh_PM_MLP_2LFac_NSTgtNFMReg_fBiPot_8DDims_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110_EENEp12876\n"
     ]
    }
   ],
   "source": [
    "assert (config.hurst == 0.5)\n",
    "assert (config.early_stop_idx == 0)\n",
    "assert (config.tdata_mult == 110)\n",
    "#assert (config.sin_space_scale == 25.)\n",
    "assert (config.feat_thresh == 1./100.)\n",
    "print(config.scoreNet_trained_path, config.dataSize)\n",
    "rng = np.random.default_rng()\n",
    "scoreModel = ConditionalMarkovianTSPostMeanScoreMatching(\n",
    "    *config.model_parameters)\n",
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "device_id = \"cpu\"\n",
    "model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "entered = False\n",
    "for file in os.listdir(model_dir):\n",
    "    if config.scoreNet_trained_path in os.path.join(model_dir, file) and \"EE\" in file:\n",
    "        print(file)\n",
    "        entered = True\n",
    "        scoreModel.load_state_dict(torch.load(os.path.join(model_dir, file)))\n",
    "assert entered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def experiment_MLP_1D_drifts(config, es,Xs, numstates,good, onlyGauss=False):\n",
    "    if config.has_cuda:\n",
    "        device = 0#int(os.environ[\"LOCAL_RANK\"])\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    Xs = torch.Tensor(Xs).to(device)\n",
    "    good = good.to(device)\n",
    "    diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "    ts_step = config.deltaT\n",
    "    Xshape = Xs.shape[0]#config.ts_length\n",
    "    num_taus = numstates\n",
    "\n",
    "    num_diff_times = config.max_diff_steps\n",
    "    Ndiff_discretisation = config.max_diff_steps\n",
    "    diffusion_times = torch.linspace(start=config.sample_eps, end=config.end_diff_time,\n",
    "                                     steps=Ndiff_discretisation).to(device)\n",
    "\n",
    "    features_tensor = torch.stack([Xs for _ in range(1)], dim=0).reshape(Xshape * 1, 1, -1).to(device)\n",
    "    vec_Z_taus = 0.1*diffusion.prior_sampling(shape=(Xshape * num_taus, 1, config.ts_dims)).to(device) #torch.zeros(size=(Xshape * num_taus, 1, config.ts_dims)).to(device)#\n",
    "    z_alt = vec_Z_taus.view(Xshape, num_taus, 1, config.ts_dims).permute(1, 0, 2, 3)\n",
    "    vec_Z_taus = z_alt.reshape(num_taus * Xshape, 1, config.ts_dims)\n",
    "    # run near the top of the function after you have features_tensor and vec_Z_taus (after you applied Fix A)\n",
    "\n",
    "    # ts = []\n",
    "    es = num_diff_times - es\n",
    "    final_vec_mu_hats = np.zeros(\n",
    "        (Xshape, es, num_taus, config.ts_dims))  # Xvalues, DiffTimes, Ztaus, Ts_Dims\n",
    "\n",
    "    ts = []\n",
    "    # mu_hats_mean = np.zeros((tot_num_feats, num_taus))\n",
    "    # mu_hats_std = np.zeros((tot_num_feats, num_taus))\n",
    "    good.eval()\n",
    "    insert_idx=-1\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for difftime_idx in (np.arange(num_diff_times - 1, num_diff_times - es - 1, -1)): #difftime_idx >= num_diff_times - es:\n",
    "            d = diffusion_times[Ndiff_discretisation - (num_diff_times - 1 - difftime_idx) - 1].to(device)\n",
    "            diff_times = torch.stack([d for _ in range(Xshape)]).reshape(Xshape * 1).to(device)\n",
    "            eff_times = diffusion.get_eff_times(diff_times=diff_times).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "            vec_diff_times = torch.stack([diff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape)\n",
    "            vec_eff_times = torch.stack([eff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape, 1, 1)\n",
    "            vec_conditioner = torch.stack([features_tensor for _ in range(num_taus)], dim=0).reshape(\n",
    "                num_taus * Xshape,\n",
    "                1, -1)\n",
    "            with torch.no_grad():\n",
    "                if onlyGauss:\n",
    "                    scoreEval_vec_Z_taus = torch.randn_like(vec_Z_taus).to(device)\n",
    "                else:\n",
    "                    scoreEval_vec_Z_taus = vec_Z_taus\n",
    "                good.eval()\n",
    "                vec_predicted_score = good.forward(inputs=scoreEval_vec_Z_taus, times=vec_diff_times, conditioner=vec_conditioner,\n",
    "                                                 eff_times=vec_eff_times)\n",
    "\n",
    "            beta_taus = torch.exp(-0.5 * eff_times[0, 0, 0]).to(device)\n",
    "            sigma_taus = torch.pow(1. - torch.pow(beta_taus, 2), 0.5).to(device)\n",
    "            sigma2_taus=torch.pow(1. - torch.pow(beta_taus, 2), 1.).to(device)\n",
    "            predicted_score = -scoreEval_vec_Z_taus/sigma2_taus + (beta_taus/sigma2_taus)*vec_predicted_score\n",
    "            vec_scores, vec_drift, vec_diffParam = diffusion.get_conditional_reverse_diffusion(x=vec_Z_taus,\n",
    "                                                                                               predicted_score=predicted_score,\n",
    "                                                                                               diff_index=torch.Tensor(\n",
    "                                                                                                   [int((\n",
    "                                                                                                           num_diff_times - 1 - difftime_idx))]).to(\n",
    "                                                                                                   device),\n",
    "                                                                                               max_diff_steps=Ndiff_discretisation)\n",
    "\n",
    "            if \"PM\" in config.scoreNet_trained_path:\n",
    "                final_mu_hats = (-beta_taus*scoreEval_vec_Z_taus / (sigma2_taus)) + ((\n",
    "                                                                                (torch.pow(sigma_taus, 2) + (\n",
    "                                                                                        torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                                2) * ts_step)) / (\n",
    "                                                                                        ts_step * sigma2_taus)) * vec_predicted_score)\n",
    "            else:\n",
    "                final_mu_hats = (scoreEval_vec_Z_taus / (ts_step * beta_taus)) + ((\n",
    "                                                                                (sigma2_taus + (\n",
    "                                                                                        torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                                2) * ts_step)) / (\n",
    "                                                                                        ts_step * beta_taus)) * vec_scores)\n",
    "\n",
    "            assert (final_mu_hats.shape == (num_taus * Xshape, 1, config.ts_dims))\n",
    "            means = final_mu_hats.reshape((num_taus, Xshape, config.ts_dims))\n",
    "\n",
    "            # print(vec_Z_taus.shape, vec_scores.shape)\n",
    "            final_vec_mu_hats[:, insert_idx,:, :] = means.permute((1, 0, 2)).cpu().numpy()\n",
    "            vec_z = torch.randn_like(vec_drift).to(device)\n",
    "            vec_Z_taus = vec_drift + vec_diffParam * vec_z\n",
    "            insert_idx -=1\n",
    "    assert (final_vec_mu_hats.shape == (Xshape, es, num_taus, config.ts_dims))\n",
    "    return final_vec_mu_hats, vec_predicted_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "numpaths = 1\n",
    "Xs = torch.ones(size=(numpaths,config.ndims))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 96.84it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 112.92it/s]\n",
      "100%|██████████| 1000/1000 [00:22<00:00, 45.31it/s]\n",
      "100%|██████████| 1000/1000 [00:22<00:00, 44.89it/s]\n",
      "100%|██████████| 1000/1000 [03:53<00:00,  4.28it/s]\n",
      "100%|██████████| 1000/1000 [04:09<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "es=9999\n",
    "numreps = 1000\n",
    "means = {k:np.inf for k in 10**(np.arange(2, 5))}\n",
    "stds = {k:np.inf for k in 10**(np.arange(2, 5))}\n",
    "for numtaus in 10**(np.arange(2, 5)):\n",
    "    oneway = []\n",
    "    for k in tqdm(range(numreps)):\n",
    "        DNonGauss, sortScore = experiment_MLP_1D_drifts(good=scoreModel,es=es, Xs=Xs, numstates=numtaus, config=config, onlyGauss=False)\n",
    "        DNonGauss = np.mean(DNonGauss[:, 0, :, :], axis=1)\n",
    "        oneway.append(DNonGauss.reshape((1, DNonGauss.shape[0], DNonGauss.shape[1])))\n",
    "    secondway = []\n",
    "    for k in tqdm(range(numreps)):\n",
    "        score_mean = multivar_score_based_MLP_drift_OOS(score_model=scoreModel,\n",
    "                                                                     num_diff_times=1,numstates=numtaus,\n",
    "                                                                     diffusion=diffusion,\n",
    "                                                                     num_paths=numpaths,\n",
    "                                                                     ts_step=config.deltaT, config=config,\n",
    "                                                                     device=device_id,\n",
    "                                                                     prev=Xs)[:, 0, :]\n",
    "        secondway.append(score_mean.reshape((1, score_mean.shape[0], score_mean.shape[1])))\n",
    "    diffs = np.concatenate(oneway, axis=0) - np.concatenate(secondway, axis=0)\n",
    "    means[numtaus] = np.mean(diffs[:, 0, :], axis=0)\n",
    "    stds[numtaus] = np.std(diffs[:, 0, :], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{100: array([-5.41801848e-05, -6.36490174e-04, -3.26590983e-03,  1.75306542e-03,\n",
      "       -1.20514088e-03,  2.69467081e-03,  1.37389101e-04, -2.62872484e-03]), 1000: array([ 6.31196675e-04,  1.53484307e-03,  1.00130148e-03,  5.78827076e-04,\n",
      "        5.94900061e-04, -1.07769726e-04,  3.30689602e-05,  1.08079680e-03]), 10000: array([-4.46129226e-05, -8.76535917e-06, -2.99972985e-04, -4.76517248e-04,\n",
      "       -3.36209077e-05, -2.25608366e-04, -9.89087103e-05, -4.71802550e-06])}\n"
     ]
    }
   ],
   "source": [
    "for"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
