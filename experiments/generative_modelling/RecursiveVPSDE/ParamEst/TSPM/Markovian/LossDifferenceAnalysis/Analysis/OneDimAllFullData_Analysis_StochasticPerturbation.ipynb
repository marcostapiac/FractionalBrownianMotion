{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "# Data parameters\n",
    "from tqdm import tqdm\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims.recursive_Markovian_PostMeanScore_fBiPot8Dims_T256_H05_tl_110data_StbleTgt_FULLDATA import get_config\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n",
    "from utils.drift_evaluation_functions import multivar_score_based_MLP_drift_OOS\n",
    "import os\n",
    "import torch\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_ax = np.linspace(0, 1/256*(256),257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type = \"score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mt622/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/trained_models/trained_rec_ST_0010FTh_PM_MLP_2LFac_NSTgtNFMReg_fBiPot_8DDims_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110 40000\n",
      "trained_rec_ST_0010FTh_PM_MLP_2LFac_NSTgtNFMReg_fBiPot_8DDims_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110_EENEp12876\n"
     ]
    }
   ],
   "source": [
    "assert (config.hurst == 0.5)\n",
    "assert (config.early_stop_idx == 0)\n",
    "assert (config.tdata_mult == 110)\n",
    "#assert (config.sin_space_scale == 25.)\n",
    "assert (config.feat_thresh == 1./100.)\n",
    "print(config.scoreNet_trained_path, config.dataSize)\n",
    "rng = np.random.default_rng()\n",
    "scoreModel = ConditionalMarkovianTSPostMeanScoreMatching(\n",
    "    *config.model_parameters)\n",
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "device_id = 0\n",
    "model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "entered = False\n",
    "for file in os.listdir(model_dir):\n",
    "    if config.scoreNet_trained_path in os.path.join(model_dir, file) and \"EE\" in file:\n",
    "        print(file)\n",
    "        entered = True\n",
    "        scoreModel.load_state_dict(torch.load(os.path.join(model_dir, file)))\n",
    "assert entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def experiment_MLP_1D_drifts(config, es,Xs, numstates,good, onlyGauss=False):\n",
    "    if config.has_cuda:\n",
    "        device = 0#int(os.environ[\"LOCAL_RANK\"])\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    Xs = torch.Tensor(Xs).to(device)\n",
    "    good = good.to(device)\n",
    "    diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "    ts_step = config.deltaT\n",
    "    Xshape = Xs.shape[0]#config.ts_length\n",
    "    num_taus = numstates\n",
    "\n",
    "    num_diff_times = config.max_diff_steps\n",
    "    Ndiff_discretisation = config.max_diff_steps\n",
    "    diffusion_times = torch.linspace(start=config.sample_eps, end=config.end_diff_time,\n",
    "                                     steps=Ndiff_discretisation).to(device)\n",
    "\n",
    "    features_tensor = torch.stack([Xs for _ in range(1)], dim=0).reshape(Xshape * 1, 1, -1).to(device)\n",
    "    vec_Z_taus = 0.1*diffusion.prior_sampling(shape=(Xshape * num_taus, 1, config.ts_dims)).to(device) #torch.zeros(size=(Xshape * num_taus, 1, config.ts_dims)).to(device)#\n",
    "    z_alt = vec_Z_taus.view(Xshape, num_taus, 1, config.ts_dims).permute(1, 0, 2, 3)\n",
    "    vec_Z_taus = z_alt.reshape(num_taus * Xshape, 1, config.ts_dims)\n",
    "    # run near the top of the function after you have features_tensor and vec_Z_taus (after you applied Fix A)\n",
    "\n",
    "    # ts = []\n",
    "    es = num_diff_times - es\n",
    "    final_vec_mu_hats = np.zeros(\n",
    "        (Xshape, es, num_taus, config.ts_dims))  # Xvalues, DiffTimes, Ztaus, Ts_Dims\n",
    "\n",
    "    ts = []\n",
    "    # mu_hats_mean = np.zeros((tot_num_feats, num_taus))\n",
    "    # mu_hats_std = np.zeros((tot_num_feats, num_taus))\n",
    "    good.eval()\n",
    "    insert_idx=-1\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for difftime_idx in (np.arange(num_diff_times - 1, num_diff_times - es - 1, -1)): #difftime_idx >= num_diff_times - es:\n",
    "            d = diffusion_times[Ndiff_discretisation - (num_diff_times - 1 - difftime_idx) - 1].to(device)\n",
    "            diff_times = torch.stack([d for _ in range(Xshape)]).reshape(Xshape * 1).to(device)\n",
    "            eff_times = diffusion.get_eff_times(diff_times=diff_times).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "            vec_diff_times = torch.stack([diff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape)\n",
    "            vec_eff_times = torch.stack([eff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape, 1, 1)\n",
    "            vec_conditioner = torch.stack([features_tensor for _ in range(num_taus)], dim=0).reshape(\n",
    "                num_taus * Xshape,\n",
    "                1, -1)\n",
    "            with torch.no_grad():\n",
    "                if onlyGauss:\n",
    "                    scoreEval_vec_Z_taus = torch.randn_like(vec_Z_taus).to(device)\n",
    "                else:\n",
    "                    scoreEval_vec_Z_taus = vec_Z_taus\n",
    "                good.eval()\n",
    "                vec_predicted_score = good.forward(inputs=scoreEval_vec_Z_taus, times=vec_diff_times, conditioner=vec_conditioner,\n",
    "                                                 eff_times=vec_eff_times)\n",
    "\n",
    "            beta_taus = torch.exp(-0.5 * eff_times[0, 0, 0]).to(device)\n",
    "            sigma_taus = torch.pow(1. - torch.pow(beta_taus, 2), 0.5).to(device)\n",
    "            sigma2_taus=torch.pow(1. - torch.pow(beta_taus, 2), 1.).to(device)\n",
    "            predicted_score = -scoreEval_vec_Z_taus/sigma2_taus + (beta_taus/sigma2_taus)*vec_predicted_score\n",
    "            vec_scores, vec_drift, vec_diffParam = diffusion.get_conditional_reverse_diffusion(x=vec_Z_taus,\n",
    "                                                                                               predicted_score=predicted_score,\n",
    "                                                                                               diff_index=torch.Tensor(\n",
    "                                                                                                   [int((\n",
    "                                                                                                           num_diff_times - 1 - difftime_idx))]).to(\n",
    "                                                                                                   device),\n",
    "                                                                                               max_diff_steps=Ndiff_discretisation)\n",
    "\n",
    "            if \"PM\" in config.scoreNet_trained_path:\n",
    "                final_mu_hats = (-beta_taus*scoreEval_vec_Z_taus / (sigma2_taus)) + ((\n",
    "                                                                                (torch.pow(sigma_taus, 2) + (\n",
    "                                                                                        torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                                2) * ts_step)) / (\n",
    "                                                                                        ts_step * sigma2_taus)) * vec_predicted_score)\n",
    "            else:\n",
    "                final_mu_hats = (scoreEval_vec_Z_taus / (ts_step * beta_taus)) + ((\n",
    "                                                                                (sigma2_taus + (\n",
    "                                                                                        torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                                2) * ts_step)) / (\n",
    "                                                                                        ts_step * beta_taus)) * vec_scores)\n",
    "\n",
    "            assert (final_mu_hats.shape == (num_taus * Xshape, 1, config.ts_dims))\n",
    "            means = final_mu_hats.reshape((num_taus, Xshape, config.ts_dims))\n",
    "\n",
    "            # print(vec_Z_taus.shape, vec_scores.shape)\n",
    "            final_vec_mu_hats[:, insert_idx,:, :] = means.permute((1, 0, 2)).cpu().numpy()\n",
    "            vec_z = torch.randn_like(vec_drift).to(device)\n",
    "            vec_Z_taus = vec_drift + vec_diffParam * vec_z\n",
    "            insert_idx -=1\n",
    "    assert (final_vec_mu_hats.shape == (Xshape, es, num_taus, config.ts_dims))\n",
    "    return final_vec_mu_hats, vec_predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpaths = 1\n",
    "Xs = torch.ones(size=(numpaths,config.ndims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m es\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9999\u001b[39m\n\u001b[1;32m      2\u001b[0m numtaus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m DNonGauss, sortScore \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment_MLP_1D_drifts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoreModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumtaus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monlyGauss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m DNonGauss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(DNonGauss[:, \u001b[38;5;241m0\u001b[39m, :, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m score_mean \u001b[38;5;241m=\u001b[39m multivar_score_based_MLP_drift_OOS(score_model\u001b[38;5;241m=\u001b[39mscoreModel,\n\u001b[1;32m      6\u001b[0m                                                                 num_diff_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,numstates\u001b[38;5;241m=\u001b[39mnumtaus,\n\u001b[1;32m      7\u001b[0m                                                                 diffusion\u001b[38;5;241m=\u001b[39mdiffusion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                 device\u001b[38;5;241m=\u001b[39mdevice_id,\n\u001b[1;32m     11\u001b[0m                                                                 prev\u001b[38;5;241m=\u001b[39mXs)[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "Cell \u001b[0;32mIn[14], line 52\u001b[0m, in \u001b[0;36mexperiment_MLP_1D_drifts\u001b[0;34m(config, es, Xs, numstates, good, onlyGauss)\u001b[0m\n\u001b[1;32m     50\u001b[0m         scoreEval_vec_Z_taus \u001b[38;5;241m=\u001b[39m vec_Z_taus\n\u001b[1;32m     51\u001b[0m     good\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 52\u001b[0m     vec_predicted_score \u001b[38;5;241m=\u001b[39m \u001b[43mgood\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoreEval_vec_Z_taus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvec_diff_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditioner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvec_conditioner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43meff_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvec_eff_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m beta_taus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m eff_times[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     56\u001b[0m sigma_taus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(beta_taus, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/models/TimeDependentScoreNetworks/ClassConditionalMarkovianTSPostMeanScoreMatching.py:233\u001b[0m, in \u001b[0;36mConditionalMarkovianTSPostMeanScoreMatching.forward\u001b[0;34m(self, inputs, times, conditioner, eff_times)\u001b[0m\n\u001b[1;32m    230\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_projection(inputs)\n\u001b[1;32m    231\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(x, \u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m diffusion_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m conditioner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_state_mapper(conditioner)\n\u001b[1;32m    235\u001b[0m cond_up \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_upsampler(conditioner)\n",
      "File \u001b[0;32m~/GitHubRepos/FractionalBrownianMotion/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHubRepos/FractionalBrownianMotion/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/models/TimeDependentScoreNetworks/ClassConditionalMarkovianTSPostMeanScoreMatching.py:27\u001b[0m, in \u001b[0;36mDiffusionEmbedding.forward\u001b[0;34m(self, diffusion_step)\u001b[0m\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding[diffusion_step]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lerp_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection1(x)\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m silu(x)\n",
      "File \u001b[0;32m~/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/models/TimeDependentScoreNetworks/ClassConditionalMarkovianTSPostMeanScoreMatching.py:39\u001b[0m, in \u001b[0;36mDiffusionEmbedding._lerp_embedding\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     37\u001b[0m low \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding[low_idx]\n\u001b[1;32m     38\u001b[0m high \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding[high_idx]\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m low \u001b[38;5;241m+\u001b[39m (t \u001b[38;5;241m-\u001b[39m low_idx)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[43mhigh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow\u001b[49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "es=9999\n",
    "numtaus = 1000000\n",
    "DNonGauss, sortScore = experiment_MLP_1D_drifts(good=scoreModel,es=es, Xs=Xs, numstates=numtaus, config=config, onlyGauss=False)\n",
    "DNonGauss = np.mean(DNonGauss[:, 0, :, :], axis=1)\n",
    "score_mean = multivar_score_based_MLP_drift_OOS(score_model=scoreModel,\n",
    "                                                                num_diff_times=1,numstates=numtaus,\n",
    "                                                                diffusion=diffusion,\n",
    "                                                                num_paths=numpaths,\n",
    "                                                                ts_step=config.deltaT, config=config,\n",
    "                                                                device=device_id,\n",
    "                                                                prev=Xs)[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.51924227  1.46273833  0.39625566  0.03105543 -1.43133404 -1.92130611\n",
      "  -1.87543001 -2.88018092]]\n",
      "[[ 2.5191877   1.462609    0.39614123  0.03092544 -1.4312199  -1.9214618\n",
      "  -1.8757219  -2.880351  ]]\n"
     ]
    }
   ],
   "source": [
    "print(DNonGauss)\n",
    "print(score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
