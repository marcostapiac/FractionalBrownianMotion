{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n",
    "from utils.drift_evaluation_functions import experiment_MLP_DDims_drifts\n",
    "from configs.RecursiveVPSDE.Markovian_8DLorenz.recursive_Markovian_PostMeanScore_8DLorenz_Stable_T256_H05_tl_110data_StbleTgt import get_config as get_8dlnz_config\n",
    "from configs.RecursiveVPSDE.Markovian_12DLorenz.recursive_Markovian_PostMeanScore_12DLorenz_Stable_T256_H05_tl_110data_StbleTgt import get_config as get_12dlnz_config\n",
    "from configs.RecursiveVPSDE.Markovian_20DLorenz.recursive_Markovian_PostMeanScore_20DLorenz_Stable_T256_H05_tl_110data_StbleTgt import get_config as get_20dlnz_config\n",
    "from configs.RecursiveVPSDE.Markovian_40DLorenz.recursive_Markovian_PostMeanScore_40DLorenz_Stable_T256_H05_tl_110data_StbleTgt import get_config as get_40dlnz_config\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.drift_evaluation_functions import multivar_score_based_MLP_drift_OOS\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "\n",
    "def _get_device(device_str: str | None = None):\n",
    "    if device_str is not None:\n",
    "        return torch.device(device_str)\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def true_drifts(device_id, config, state):\n",
    "    true_drifts = np.zeros_like(state)\n",
    "    for i in range(config.ndims):\n",
    "        true_drifts[:, i] = (state[:, (i + 1) % config.ndims] - state[:, i - 2]) * state[:, i - 1] - state[:,i] * config.forcing_const\n",
    "    return torch.tensor(true_drifts[:, np.newaxis, :], device=device_id, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "lnz_8d_config = get_8dlnz_config()\n",
    "lnz_12d_config = get_12dlnz_config()\n",
    "lnz_20d_config = get_20dlnz_config()\n",
    "lnz_40d_config = get_40dlnz_config()\n",
    "device_id = _get_device()\n",
    "root_dir =\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def generate_synthetic_paths(config, device_id, good):\n",
    "    diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "    num_diff_times = 1\n",
    "    rmse_quantile_nums = 1\n",
    "    num_paths = 200\n",
    "    num_time_steps = config.ts_length\n",
    "    deltaT = config.deltaT\n",
    "    all_true_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, config.ndims))\n",
    "    all_global_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, config.ndims))\n",
    "    all_local_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, config.ndims))\n",
    "    for quant_idx in tqdm(range(rmse_quantile_nums)):\n",
    "        good.eval()\n",
    "        initial_state = np.repeat(np.atleast_2d(config.initState)[np.newaxis, :], num_paths, axis=0)\n",
    "        assert (initial_state.shape == (num_paths, 1, config.ndims))\n",
    "\n",
    "        true_states = np.zeros(shape=(num_paths, 1 + num_time_steps, config.ndims))\n",
    "        global_states = np.zeros(shape=(num_paths, 1 + num_time_steps, config.ndims))\n",
    "        local_states = np.zeros(shape=(num_paths, 1 + num_time_steps, config.ndims))\n",
    "\n",
    "        # Initialise the \"true paths\"\n",
    "        true_states[:, [0], :] = initial_state + 0.00001 * np.random.randn(*initial_state.shape)\n",
    "        # Initialise the \"global score-based drift paths\"\n",
    "        global_states[:, [0], :] = true_states[:, [0], :]\n",
    "        local_states[:, [0], :] = true_states[:, [0],\n",
    "                                  :]  # np.repeat(initial_state[np.newaxis, :], num_diff_times, axis=0)\n",
    "\n",
    "        # Euler-Maruyama Scheme for Tracking Errors\n",
    "        for i in range(1, num_time_steps + 1):\n",
    "            eps = np.random.randn(num_paths, 1, config.ndims) * np.sqrt(deltaT) * config.diffusion\n",
    "\n",
    "            assert (eps.shape == (num_paths, 1, config.ndims))\n",
    "            true_mean = true_drifts(state=true_states[:, i - 1, :], device_id=device_id,config=config).numpy()\n",
    "            denom = 1.\n",
    "            global_mean = multivar_score_based_MLP_drift_OOS(score_model=good,\n",
    "                                                             num_diff_times=num_diff_times,\n",
    "                                                             diffusion=diffusion,\n",
    "                                                             num_paths=num_paths,\n",
    "                                                             ts_step=deltaT, config=config,\n",
    "                                                             device=device_id,\n",
    "                                                             prev=global_states[:, i - 1, :])\n",
    "\n",
    "            true_states[:, [i], :] = (true_states[:, [i - 1], :] \\\n",
    "                                      + true_mean * deltaT \\\n",
    "                                      + eps) / denom\n",
    "            global_states[:, [i], :] = (global_states[:, [i - 1], :] + global_mean * deltaT + eps) / denom\n",
    "\n",
    "        all_true_states[quant_idx, :, :, :] = true_states\n",
    "        all_global_states[quant_idx, :, :, :] = global_states\n",
    "    return all_true_states, all_local_states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "\n",
    "def get_best_epoch(config, type):\n",
    "    model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "    for file in os.listdir(model_dir):\n",
    "        if config.scoreNet_trained_path in os.path.join(model_dir, file) and f\"{type}\" in file:\n",
    "            best_epoch = int(file.split(f\"{type}NEp\")[-1])\n",
    "    return best_epoch\n",
    "\n",
    "def get_best_track_file(root_score_dir, ts_type, best_epoch_track):\n",
    "    for file in os.listdir(root_score_dir):\n",
    "        if (\"_\"+str(best_epoch_track)+\"Nep\") in file and \"true\" in file and ts_type in file and \"1000FTh\" in file and \"125FConst\" in file:\n",
    "            with open(root_score_dir+file, 'rb') as f:\n",
    "                buf = io.BytesIO(f.read())  # hydrates once, sequentially\n",
    "            true_file = np.load(root_score_dir+file, allow_pickle=True)\n",
    "        elif (\"_\"+str(best_epoch_track)+\"Nep\") in file and \"global\" in file and ts_type in file and \"1000FTh\" in file and \"125FConst\" in file:\n",
    "            with open(root_score_dir+file, 'rb') as f:\n",
    "                buf = io.BytesIO(f.read())  # hydrates once, sequentially\n",
    "            global_file = np.load(root_score_dir+file, allow_pickle=True)\n",
    "    print(ts_type)\n",
    "    return true_file, global_file\n",
    "\n",
    "def get_best_eval_exp_file(config, root_score_dir, ts_type):\n",
    "    best_epoch_eval = get_best_epoch(config=config,type=\"EE\")\n",
    "    for file in os.listdir(root_score_dir):\n",
    "        if (\"_\"+str(best_epoch_eval)+\"Nep\") in file and \"MSE\" in file and ts_type in file and \"1000FTh\" in file and \"125FConst\" in file:\n",
    "            print(f\"Starting {file}\\n\")\n",
    "            with open(root_score_dir+file, 'rb') as f:\n",
    "                buf = io.BytesIO(f.read())  # hydrates once, sequentially\n",
    "            print(f\"Starting {file}\\n\")\n",
    "            mse = pd.read_parquet(root_score_dir+file, engine=\"fastparquet\")\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8DLnz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 12DLnz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 20DLnz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 40DLnz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.46s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_tracks = {t: np.inf for t in [\"8DLnz\", \"12DLnz\", \"20DLnz\", \"40DLnz\"]}\n",
    "for config in [lnz_8d_config, lnz_12d_config, lnz_20d_config, lnz_40d_config]:\n",
    "    assert config.feat_thresh == 1.\n",
    "    assert config.forcing_const == 1.25\n",
    "    Xshape = config.ts_length\n",
    "    root_score_dir = root_dir\n",
    "    label = \"$\\mu_{5}$\"\n",
    "    if \"8DLnz\" in config.data_path:\n",
    "        root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/8DLnzLessData/\"\n",
    "        ts_type = \"8DLnz\"\n",
    "    elif \"12DLnz\" in config.data_path:\n",
    "        root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/12DLnzLessData/\"\n",
    "        ts_type = \"12DLnz\"\n",
    "    elif \"20DLnz\" in config.data_path:\n",
    "        root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/20DLnzLessData/\"\n",
    "        ts_type = \"20DLnz\"\n",
    "    elif \"40DLnz\" in config.data_path:\n",
    "        root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/40DLnzLessData/\"\n",
    "        ts_type = \"40DLnz\"\n",
    "    print(f\"Starting {ts_type}\\n\")\n",
    "    model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "    entered = False\n",
    "    best_epoch = get_best_epoch(config=config,type=\"EE\")\n",
    "    for file in os.listdir(model_dir):\n",
    "        if config.scoreNet_trained_path in os.path.join(model_dir, file) and (\"EE\" in file and \"Trk\" not in file) and str(best_epoch) in file:\n",
    "            good = ConditionalMarkovianTSPostMeanScoreMatching(\n",
    "        *config.model_parameters)\n",
    "            entered = True\n",
    "            good.load_state_dict(torch.load(os.path.join(model_dir, file)))\n",
    "    assert entered\n",
    "    all_true_paths, all_global_paths = generate_synthetic_paths(config=config, device_id=device_id, good=good)\n",
    "    all_true_paths = all_true_paths.reshape(-1, config.ts_length+1, config.ts_dims)\n",
    "    all_global_paths = all_global_paths.reshape(-1, config.ts_length+1, config.ts_dims)\n",
    "    all_true_states = all_true_paths[:, 1:,:].reshape(-1, config.ts_dims)\n",
    "    all_global_states = torch.tensor(all_global_paths[:, 1:,:].reshape(-1, config.ts_dims), device=device_id, dtype=torch.float32)\n",
    "    true_drift = true_drifts(state=all_true_states, device_id=device_id,config=config).numpy()\n",
    "    drift_ests = experiment_MLP_DDims_drifts(config=config, Xs=all_global_states, good=good, onlyGauss=False)\n",
    "    drift_ests= drift_ests[:, -1, :, :].reshape(drift_ests.shape[0],drift_ests.shape[2],drift_ests.shape[\n",
    "                                                                                               -1] * 1).mean(axis=1)\n",
    "    mse = np.mean(np.sum(np.power(true_drift - drift_ests,2), axis=-1))\n",
    "    eval_tracks[ts_type] = mse\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "{'8DLnz': 513.88196,\n '12DLnz': 520.7596,\n '20DLnz': 1338.998,\n '40DLnz': 1332.6201}"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tracks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
