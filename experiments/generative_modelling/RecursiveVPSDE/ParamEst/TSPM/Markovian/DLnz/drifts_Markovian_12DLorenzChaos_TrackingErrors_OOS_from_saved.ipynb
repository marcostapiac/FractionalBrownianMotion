{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from configs import project_config\n",
    "from configs.RecursiveVPSDE.Markovian_12DLorenz.recursive_Markovian_PostMeanScore_12DLorenz_Chaos_T256_H05_tl_110data_StbleTgt import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def rmse_ignore_nans(y_true, y_pred):\n",
    "    assert (y_true.shape[0] == y_pred.shape[0])\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)  # Ignore NaNs in both arrays\n",
    "    return (np.mean((y_true[mask] - y_pred[mask]) ** 2))\n",
    "\n",
    "def plot_ewma_losses(epochs, losses):\n",
    "    start_idx = 00\n",
    "    def compute_ema(loss_tensor, beta):\n",
    "        ema_values = np.zeros_like(loss_tensor)  # Initialize EMA tensor\n",
    "        ema_values[0] = loss_tensor[0]  # First value stays the same\n",
    "\n",
    "        for i in range(1, len(loss_tensor)):\n",
    "            ema_values[i] = beta * ema_values[i - 1] + (1 - beta) * loss_tensor[i]\n",
    "\n",
    "        return ema_values\n",
    "    # Define EMA decay rates\n",
    "    beta_short = 0.9   # Short-term trend (reacts quickly)\n",
    "    beta_long = 0.99   # Long-term trend (smoother)\n",
    "\n",
    "    # Compute EMAs\n",
    "    short_term_ema = compute_ema(losses, beta_short)\n",
    "    long_term_ema = compute_ema(losses, beta_long)\n",
    "    plt.scatter(epochs[start_idx:], (short_term_ema[start_idx:]),s=2, label=\"Short Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.scatter(epochs[start_idx:], (long_term_ema[start_idx:]),s=2, label=\"Long Term Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "config = get_config()\n",
    "deltaT = config.deltaT\n",
    "root_dir =\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/\"\n",
    "print(config.loss_factor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/marcos/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/training_losses/trained_rec_PM_ST_1000FTh_MLP_2LFac_NSTgtNFMReg_12DLnz_125e+00FConst_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_MLP_H4_CUp20_tl110_loss'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscoreNet_trained_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/trained_models/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/training_losses/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      2\u001B[0m         losses \u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39marray(pickle\u001B[38;5;241m.\u001B[39mload(f))\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m))\n\u001B[1;32m      3\u001B[0m Nepochs_losses \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(losses\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/GitHubRepos/FractionalBrownianMotion/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/marcos/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/training_losses/trained_rec_PM_ST_1000FTh_MLP_2LFac_NSTgtNFMReg_12DLnz_125e+00FConst_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_MLP_H4_CUp20_tl110_loss'"
     ]
    }
   ],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = (np.array(pickle.load(f)).astype(float))\n",
    "Nepochs_losses = np.arange(losses.shape[0])\n",
    "plt.scatter(Nepochs_losses,  losses, s=10)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "Nepochs_losses[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ewma_losses(epochs=Nepochs_losses, losses=losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "root_score_dir = root_dir + f\"ExperimentResults/TSPM_Markovian/20DLnz/\"\n",
    "mses=[]\n",
    "for file in os.listdir(root_score_dir):\n",
    "    if \"MSE\" in file:\n",
    "        mses.append(pd.read_parquet(root_score_dir+file, engine=\"fastparquet\"))\n",
    "mses = pd.concat(mses).reset_index(drop=False).rename({\"index\":\"epoch\"}, axis=1).sort_values(\"epoch\").reset_index(drop=True)\n",
    "Nepochs_track = mses[\"epoch\"].values.flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss_LR\", 'rb') as f:\n",
    "        LRs = (np.array(pickle.load(f)).astype(float))\n",
    "start = 0#935\n",
    "end = -1#935+152\n",
    "plt.scatter(Nepochs_losses[start:end],  LRs[start:end], s=10, label=\"Learning Rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(end-start+1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(config.scoreNet_trained_path.replace(\"/trained_models/\", \"/training_losses/\") + \"_loss\", 'rb') as f:\n",
    "        losses = np.array(pickle.load(f)).astype(float)\n",
    "Nepochs_losses = np.arange(losses.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "common_epochs = np.intersect1d(Nepochs_losses, Nepochs_track)\n",
    "common_epochs = np.intersect1d(common_epochs, np.arange(1, 3000))\n",
    "print(common_epochs, Nepochs_track)\n",
    "start_idx = 0\n",
    "common_epochs = common_epochs[start_idx:]\n",
    "losses_idx = [np.argwhere(c == Nepochs_losses)[0,0] for c in common_epochs]\n",
    "track_idx = [np.argwhere(c == Nepochs_track)[0,0] for c in common_epochs]\n",
    "red_losses = losses[losses_idx]\n",
    "print(np.array(list(drift_track_rmses.values())).shape, track_idx)\n",
    "track_rmses = np.array(list(drift_track_rmses.values()))[track_idx]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "toSave = False\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "sc1 = ax.scatter(common_epochs, red_losses, s=10, label=\"Training Loss\")\n",
    "ax2 = ax.twinx()\n",
    "sc2 = ax2.scatter(common_epochs, track_rmses, s=20, color=\"red\",label=\"Tracking MSE\")\n",
    "ax.set_xlabel(\"Training Epochs\", fontsize=38)\n",
    "ax.set_title(r\"Losses for $\\mu_{6}$\", fontsize=40)\n",
    "ax.tick_params(axis=\"both\",labelsize=24)\n",
    "ax2.tick_params(axis=\"both\",labelsize=24)\n",
    "#ax.set_yscale(\"log\")\n",
    "#ax2.set_yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "handles = [sc1, sc2]\n",
    "labels = [h.get_label() for h in handles]\n",
    "# Add a single legend on ax1\n",
    "ax.legend(handles, labels, fontsize=24)\n",
    "if toSave:\n",
    "    plt.savefig((f\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/DiffusionModelPresentationImages/TSPM_Markovian/12DLnzChaos/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_{config.ndims}DLnz_{config.forcing_const}FConst_LossesTrack_{config.loss_factor}LFac\").replace(\".\",\"\")+\".png\",  bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr_rmse = np.inf\n",
    "toSave = False\n",
    "for f_idx in range(len(common_epochs)):\n",
    "    Nepoch = common_epochs[f_idx]\n",
    "    ff_idx = np.argwhere(Nepoch == np.array(epochs_iter))[0,0]\n",
    "    true = drift_true_files[ff_idx]\n",
    "    local = drift_local_files[ff_idx]\n",
    "    try:\n",
    "        num_diff_times = 1\n",
    "        all_true_states = np.load(true)\n",
    "        all_local_states= np.load(local)\n",
    "        time_steps = np.linspace(config.t0,config.deltaT*all_true_states.shape[2],all_true_states.shape[2])\n",
    "        all_global_errors = np.sum(np.power(all_true_states- all_local_states,2), axis=-1)\n",
    "        all_global_errors=all_global_errors.reshape(-1, all_global_errors.shape[-1])            # (K, N, T)\n",
    "        total_local_errors = np.sqrt(np.mean(all_global_errors, axis=(0)))/np.sqrt(time_steps)\n",
    "        all_paths_err = np.sqrt(all_global_errors)/np.sqrt(time_steps)\n",
    "        total_local_errors[total_local_errors==np.inf] = 0.\n",
    "        all_paths_err[all_paths_err==np.inf] = 0.\n",
    "        total_local_errors_minq, total_local_errors_maxq  = np.quantile(all_paths_err, q=[0.005, 0.995], axis=0) # (T,)<\n",
    "        if total_local_errors[-1] < curr_rmse:\n",
    "            curr_rmse = total_local_errors[-1]\n",
    "            fig, ax = plt.subplots(figsize=(14,9))\n",
    "            plt.grid(True)\n",
    "            ax.scatter(time_steps, total_local_errors)\n",
    "            plt.fill_between(time_steps,y1=total_local_errors_minq, y2=total_local_errors_maxq, color=\"blue\", alpha=0.4)\n",
    "            ax.set_title(rf\"Pathwise RMSE for Score Estimator for $\\mu_5$\",fontsize=40)\n",
    "            ax.set_ylabel(\"RMSE\", fontsize=38)\n",
    "            ax.set_xlabel(\"Time Axis\", fontsize=38)\n",
    "            ax.tick_params(labelsize=38)\n",
    "            plt.tight_layout()\n",
    "            if toSave:\n",
    "                plt.savefig((f\"/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/DiffusionModelPresentationImages/TSPM_Markovian/12DLnzChaos/TSPM_MLP_PM_ST_{config.feat_thresh:.3f}FTh_{config.ndims}DLnz_DriftTrack_{Nepoch}Nep_{config.forcing_const}FConst_{round(total_local_errors_minq[-1], 8)}_MinIQR_{round(total_local_errors[-1], 8)}MeanIQR_{round(total_local_errors_maxq[-1], 8)}_MaxIQR\").replace(\".\", \"\")+\".png\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(f\"Final time cumulative MSE local-time error {total_local_errors[-1]} with final IQR {(total_local_errors_minq[-1], total_local_errors_maxq[-1])} at Nepoch {Nepoch} for {config.forcing_const}FConst\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
