{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from configs import project_config\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from src.classes.ClassConditionalStbleTgtMarkovianPostMeanDiffTrainer import \\\n",
    "    ConditionalStbleTgtMarkovianPostMeanDiffTrainer\n",
    "from src.generative_modelling.data_processing import train_and_save_recursive_diffusion_model\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n",
    "from utils.data_processing import init_experiment, cleanup_experiment\n",
    "from utils.math_functions import generate_fQuadSin\n",
    "from utils.resource_logger import ResourceLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims_NonSep.recursive_Markovian_PostMeanScore_fBiPot8DimsNS_T256_H05_tl_110data_StbleTgt import get_config\n",
    "config = get_config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/marcos/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/trained_models/trained_rec_ST_0010FTh_PM_MLP_2LFac_fBiPot_8DDimsNS_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110 40000\n"
     ]
    }
   ],
   "source": [
    "assert (config.hurst == 0.5)\n",
    "assert (config.early_stop_idx == 0)\n",
    "assert (config.tdata_mult == 110)\n",
    "assert (config.feat_thresh == 1./100.)\n",
    "print(config.scoreNet_trained_path, config.dataSize)\n",
    "rng = np.random.default_rng()\n",
    "scoreModel = ConditionalMarkovianTSPostMeanScoreMatching(\n",
    "    *config.model_parameters)\n",
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_rec_ST_0010FTh_PM_MLP_2LFac_fBiPot_8DDimsNS_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_025a_-20b_00c_MLP_H4_CUp20_tl110_EENEp260\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "entered = False\n",
    "for file in os.listdir(model_dir):\n",
    "    if config.scoreNet_trained_path in os.path.join(model_dir, file) and \"EE\" in file:\n",
    "        print(file)\n",
    "        entered = True\n",
    "        scoreModel.load_state_dict(torch.load(os.path.join(model_dir, file)))\n",
    "assert entered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def true_drift(prev, num_paths, config):\n",
    "    assert (prev.shape == (num_paths, config.ndims))\n",
    "    drift_X = -(4. * np.array(config.quartic_coeff) * np.power(prev,\n",
    "                                                                 3) + 2. * np.array(config.quad_coeff) * prev + np.array(config.const))\n",
    "    xstar = np.sqrt(\n",
    "        np.maximum(1e-12, -np.array(config.quad_coeff) / (2.0 * np.array(config.quartic_coeff))))\n",
    "    s2 = (config.scale * xstar) ** 2 + 1e-12  # (D,) or (K,1,D)\n",
    "    diff = prev ** 2 - xstar ** 2  # same shape as prev\n",
    "    phi = np.exp(-(diff ** 2) / (2.0 * s2 * xstar ** 2 + 1e-12))\n",
    "    phi_prime = phi * (-2.0 * prev * diff / ((config.scale ** 2) * (xstar ** 4 + 1e-12)))\n",
    "    nbr = np.roll(phi, 1, axis=-1) + np.roll(phi, -1, axis=-1)  # same shape as phi\n",
    "    drift_X = drift_X - 0.5 * config.coupling * phi_prime * nbr\n",
    "    return drift_X[:, np.newaxis, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def experiment_multivar_score_based_MLP_drift_OOS(score_model, num_diff_times, diffusion, num_paths, prev,\n",
    "                                       ts_step, config,\n",
    "                                       device, onlyGauss):\n",
    "    \"\"\" Computes drift using MLP score network when features obtained from LSTM directly \"\"\"\n",
    "\n",
    "    score_model = score_model.to(device)\n",
    "    num_taus = 100\n",
    "    Ndiff_discretisation = config.max_diff_steps\n",
    "    assert (prev.shape == (num_paths, config.ndims))\n",
    "    assert (prev[0, :].shape[0] == config.ts_dims)\n",
    "    features_tensor = torch.stack([torch.tensor(prev, dtype=torch.float32) for _ in range(1)], dim=0).reshape(\n",
    "        num_paths * 1, 1, -1).to(device)\n",
    "    assert (features_tensor.shape[0] == num_paths)\n",
    "    vec_Z_taus = diffusion.prior_sampling(shape=(num_paths * num_taus, 1, config.ts_dims)).to(device)\n",
    "\n",
    "    diffusion_times = torch.linspace(config.sample_eps, 1., config.max_diff_steps)\n",
    "    difftime_idx = Ndiff_discretisation - 1\n",
    "    for difftime_idx in tqdm(np.arange(num_diff_times - 1, num_diff_times - es - 1, -1)): #difftime_idx >= num_diff_times - es:\n",
    "        d = diffusion_times[difftime_idx].to(device)\n",
    "        diff_times = torch.stack([d for _ in range(num_paths)]).reshape(num_paths * 1).to(device)\n",
    "        eff_times = diffusion.get_eff_times(diff_times=diff_times).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        vec_diff_times = torch.stack([diff_times for _ in range(num_taus)], dim=0).reshape(num_taus * num_paths)\n",
    "        vec_eff_times = torch.stack([eff_times for _ in range(num_taus)], dim=0).reshape(num_taus * num_paths, 1, 1)\n",
    "        vec_conditioner = torch.stack([features_tensor for _ in range(num_taus)], dim=0).reshape(\n",
    "            num_taus * num_paths,\n",
    "            1, -1)\n",
    "        score_model.eval()\n",
    "        with torch.no_grad():\n",
    "            if onlyGauss:\n",
    "                scoreEval_vec_Z_taus = diffusion.prior_sampling(shape=vec_Z_taus.shape).to(device)\n",
    "            else:\n",
    "                scoreEval_vec_Z_taus = vec_Z_taus\n",
    "            vec_predicted_score = score_model.forward(times=vec_diff_times, eff_times=vec_eff_times,\n",
    "                                                      conditioner=vec_conditioner, inputs=scoreEval_vec_Z_taus)\n",
    "        vec_scores, vec_drift, vec_diffParam = diffusion.get_conditional_reverse_diffusion(x=vec_Z_taus,\n",
    "                                                                                           predicted_score=vec_predicted_score,\n",
    "                                                                                           diff_index=torch.Tensor(\n",
    "                                                                                               [int((\n",
    "                                                                                                       num_diff_times - 1 - difftime_idx))]).to(\n",
    "                                                                                               device),\n",
    "                                                                                           max_diff_steps=Ndiff_discretisation)\n",
    "        # assert np.allclose((scores- predicted_score).detach(), 0)\n",
    "        beta_taus = torch.exp(-0.5 * eff_times[0, 0, 0]).to(device)\n",
    "        sigma_taus = torch.pow(1. - torch.pow(beta_taus, 2), 0.5).to(device)\n",
    "        final_mu_hats = (vec_Z_taus / (ts_step * beta_taus)) + ((\n",
    "                                                                        (torch.pow(sigma_taus, 2) + (\n",
    "                                                                                torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                          2) * ts_step)) / (\n",
    "                                                                                ts_step * beta_taus)) * vec_scores)\n",
    "\n",
    "        assert (final_mu_hats.shape == (num_taus * num_paths, 1, config.ts_dims))\n",
    "        means = final_mu_hats.reshape((num_taus, num_paths, config.ts_dims))\n",
    "        assert (means.shape == (num_taus, num_paths, config.ts_dims))\n",
    "        # print(vec_Z_taus.shape, vec_scores.shape)\n",
    "        vec_z = torch.randn_like(vec_drift).to(device)\n",
    "        vec_Z_taus = vec_drift + vec_diffParam * vec_z\n",
    "    return means.mean(dim=0).reshape(num_paths, 1, num_diff_times, config.ts_dims).cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weak_error_computation(config, score_network, num_time_steps, onlyGauss):\n",
    "    num_diff_times = num_time_steps\n",
    "    rmse_quantile_nums = 2\n",
    "    num_paths = 100\n",
    "    num_time_steps = 256\n",
    "    all_true_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "    all_global_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "    all_local_states = np.zeros(shape=(rmse_quantile_nums, num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "    deltaT = config.deltaT\n",
    "    for quant_idx in tqdm(range(rmse_quantile_nums)):\n",
    "        score_network.eval()\n",
    "        initial_state = np.repeat(np.atleast_2d(config.initState)[np.newaxis, :], num_paths, axis=0)\n",
    "        assert (initial_state.shape == (num_paths, 1, num_diff_times, config.ndims))\n",
    "\n",
    "        true_states = np.zeros(shape=(num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "        global_states = np.zeros(shape=(num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "        local_states = np.zeros(shape=(num_paths, 1 + num_time_steps, num_diff_times, config.ndims))\n",
    "\n",
    "        # Initialise the \"true paths\"\n",
    "        true_states[:, [0], :] = initial_state + 0.00001 * np.random.randn(*initial_state.shape)\n",
    "        # Initialise the \"global score-based drift paths\"\n",
    "        global_states[:, [0], :] = true_states[:, [0], :]\n",
    "        local_states[:, [0], :] = true_states[:, [0], :]  # np.repeat(initial_state[np.newaxis, :], num_diff_times, axis=0)\n",
    "\n",
    "        # Euler-Maruyama Scheme for Tracking Errors\n",
    "        for i in range(1, num_time_steps + 1):\n",
    "            eps = np.random.randn(num_paths, 1, num_diff_times, config.ndims) * np.sqrt(deltaT)*config.diffusion\n",
    "            assert (eps.shape == (num_paths, 1, num_diff_times, config.ndims))\n",
    "            true_mean = true_drift(true_states[:, i - 1, :, :], num_paths=num_paths, config=config)\n",
    "            denom = 1.\n",
    "            local_mean = experiment_multivar_score_based_MLP_drift_OOS(\n",
    "                score_model=score_network,\n",
    "               num_diff_times=num_diff_times,\n",
    "                diffusion=diffusion,\n",
    "                num_paths=num_paths, ts_step=deltaT,\n",
    "                config=config,\n",
    "                device=score_network.device,\n",
    "                prev=true_states[:, i - 1,:, :], onlyGauss=onlyGauss)\n",
    "\n",
    "            global_mean = experiment_multivar_score_based_MLP_drift_OOS(score_model=score_network,\n",
    "                                                                                  num_diff_times=num_diff_times,\n",
    "                                                                                  diffusion=diffusion,\n",
    "                                                                                  num_paths=num_paths,\n",
    "                                                                                  ts_step=deltaT, config=config,\n",
    "                                                                                  device=score_network.device,\n",
    "                                                                                  prev=global_states[:, i - 1,:,  :], onlyGauss=onlyGauss)\n",
    "\n",
    "            true_states[:, [i], :,:] = (true_states[:, [i - 1], :, :] \\\n",
    "                                     + true_mean * deltaT \\\n",
    "                                     + eps)/denom\n",
    "            local_states[:, [i], :,:] = (true_states[:, [i - 1], :, :] + local_mean * deltaT + eps)/denom\n",
    "            global_states[:, [i], :,:] = (global_states[:, [i - 1], :, :] + global_mean * deltaT + eps)/denom\n",
    "\n",
    "        all_true_states[quant_idx, :, :, :, :] = true_states\n",
    "        all_local_states[quant_idx, :, :, :,:] = local_states\n",
    "        all_global_states[quant_idx, :, :,:, :] = global_states\n",
    "    return all_true_states, all_local_states, all_global_states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Min :  0.0\n",
      "Using CPU\n",
      "\n",
      "/Users/marcos/GitHubRepos/FractionalBrownianMotion/src/generative_modelling/trained_models/trained_rec_ST_0002FTh_PM_MLP_2LFac_NFMReg_fQuadSinHF_VPSDE_T256_Ndiff10000_Tdiff1000e+00_DiffEmbSz64_ResLay10_ResChan8_DiffHdnSz64_TrueHybd_TrueWghts_t00_dT3906e-03_05a_004b_250c_MLP_H4_CUp20_tl110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 6868/10000 [25:20<11:33,  4.52it/s]  \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onlyGauss = True\n",
    "true_state, local_states, global_states = weak_error_computation(score_network=scoreModel, num_time_steps=config.max_diff_steps, onlyGauss=onlyGauss ,config=config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/marcos/GitHubRepos/FractionalBrownianMotion/data/'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_file_path = project_config.ROOT_DIR+\"data/\" #/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/ExperimentResults/\"\n",
    "remote_file_path\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(remote_file_path + \"8DDimsBiPotNonSep_optimal_tau_experiment_DGauss.npy\", true_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DGauss = np.load(remote_file_path + \"QuadSinHF_optimal_tau_experiment_DGauss.npy\", allow_pickle=True)\n",
    "DNonGauss = np.load(remote_file_path + \"QuadSinHF_optimal_tau_experiment_DNonGauss.npy\", allow_pickle=True)\n",
    "Xshape = 256\n",
    "Xs = np.linspace(-1.5, 1.5, num=Xshape)\n",
    "true_drifts = (-2. * config.quad_coeff * Xs + config.sin_coeff * config.sin_space_scale * np.sin(config.sin_space_scale * Xs))[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "Gauss_errors = np.mean(DGauss, axis=2) - true_drifts\n",
    "assert np.all(Gauss_errors.shape == (Xshape, DGauss.shape[1], config.ts_dims))\n",
    "NonGauss_errors = np.mean(DNonGauss, axis=2) - true_drifts\n",
    "assert np.all(NonGauss_errors.shape == (Xshape, DNonGauss.shape[1], config.ts_dims))\n",
    "Gauss_errors = np.sum(np.power(Gauss_errors,2), axis=-1)\n",
    "NonGauss_errors = np.sum(np.power(NonGauss_errors,2), axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
