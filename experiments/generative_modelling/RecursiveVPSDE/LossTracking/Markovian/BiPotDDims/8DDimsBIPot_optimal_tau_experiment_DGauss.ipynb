{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site, pathlib, subprocess, sys\n",
    "sys.path.insert(0,\"/home/mt622/GitHubRepos/FractionalBrownianMotion\")\n",
    "repo_root = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], text=True\n",
    ").strip()\n",
    "pth_dir = pathlib.Path(site.getsitepackages()[0])\n",
    "(pth_dir / \"namerepo_root.pth\").write_text(repo_root + \"\\n\")\n",
    "print(\"Wrote\", pth_dir / \"namerepo_root.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from configs import project_config\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from src.classes.ClassConditionalStbleTgtMarkovianPostMeanDiffTrainer import \\\n",
    "    ConditionalStbleTgtMarkovianPostMeanDiffTrainer\n",
    "from src.generative_modelling.data_processing import train_and_save_recursive_diffusion_model\n",
    "from src.generative_modelling.models.ClassVPSDEDiffusion import VPSDEDiffusion\n",
    "from src.generative_modelling.models.TimeDependentScoreNetworks.ClassConditionalMarkovianTSPostMeanScoreMatching import \\\n",
    "    ConditionalMarkovianTSPostMeanScoreMatching\n",
    "from utils.data_processing import init_experiment, cleanup_experiment\n",
    "from utils.math_functions import generate_fQuadSin\n",
    "from utils.resource_logger import ResourceLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "from configs.RecursiveVPSDE.Markovian_fBiPotDDims.recursive_Markovian_PostMeanScore_fBiPot8Dims_T256_H05_tl_110data_StbleTgt import get_config\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (config.hurst == 0.5)\n",
    "assert (config.early_stop_idx == 0)\n",
    "assert (config.tdata_mult == 110)\n",
    "#assert (config.sin_space_scale == 25.)\n",
    "assert (config.feat_thresh == 1./100.)\n",
    "print(config.scoreNet_trained_path, config.dataSize)\n",
    "rng = np.random.default_rng()\n",
    "scoreModel = ConditionalMarkovianTSPostMeanScoreMatching(\n",
    "    *config.model_parameters)\n",
    "diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dir = \"/\".join(config.scoreNet_trained_path.split(\"/\")[:-1]) + \"/\"\n",
    "entered = False\n",
    "for file in os.listdir(model_dir):\n",
    "    if config.scoreNet_trained_path in os.path.join(model_dir, file) and \"EE\" in file:\n",
    "        print(file)\n",
    "        entered = True\n",
    "        scoreModel.load_state_dict(torch.load(os.path.join(model_dir, file)))\n",
    "assert entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def experiment_MLP_1D_drifts(config, es,Xs, good, onlyGauss=False):\n",
    "    print(\"Beta Min : \", config.beta_min)\n",
    "    if config.has_cuda:\n",
    "        device = 0#int(os.environ[\"LOCAL_RANK\"])\n",
    "    else:\n",
    "        print(\"Using CPU\\n\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    Xs = torch.Tensor(Xs).to(device)\n",
    "    good = good.to(device)\n",
    "    diffusion = VPSDEDiffusion(beta_max=config.beta_max, beta_min=config.beta_min)\n",
    "    ts_step = config.deltaT\n",
    "    print(config.scoreNet_trained_path)\n",
    "    Xshape = config.ts_length\n",
    "    num_taus = 10\n",
    "\n",
    "    num_diff_times = config.max_diff_steps\n",
    "    Ndiff_discretisation = config.max_diff_steps\n",
    "    diffusion_times = torch.linspace(start=config.sample_eps, end=config.end_diff_time,\n",
    "                                     steps=Ndiff_discretisation).to(device)\n",
    "\n",
    "    features_tensor = torch.stack([Xs for _ in range(1)], dim=0).reshape(Xshape * 1, 1, -1).to(device)\n",
    "    vec_Z_taus = diffusion.prior_sampling(shape=(Xshape * num_taus, 1, config.ts_dims)).to(device)\n",
    "\n",
    "    # ts = []\n",
    "    es = num_diff_times - es\n",
    "    final_vec_mu_hats = np.zeros(\n",
    "        (Xshape, es, num_taus, config.ts_dims))  # Xvalues, DiffTimes, Ztaus, Ts_Dims\n",
    "    \n",
    "    ts = []\n",
    "    # mu_hats_mean = np.zeros((tot_num_feats, num_taus))\n",
    "    # mu_hats_std = np.zeros((tot_num_feats, num_taus))\n",
    "    good.eval()\n",
    "    insert_idx=-1\n",
    "    for difftime_idx in tqdm(np.arange(num_diff_times - 1, num_diff_times - es - 1, -1)): #difftime_idx >= num_diff_times - es:\n",
    "        d = diffusion_times[Ndiff_discretisation - (num_diff_times - 1 - difftime_idx) - 1].to(device)\n",
    "        diff_times = torch.stack([d for _ in range(Xshape)]).reshape(Xshape * 1).to(device)\n",
    "        eff_times = diffusion.get_eff_times(diff_times=diff_times).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        vec_diff_times = torch.stack([diff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape)\n",
    "        vec_eff_times = torch.stack([eff_times for _ in range(num_taus)], dim=0).reshape(num_taus * Xshape, 1, 1)\n",
    "        vec_conditioner = torch.stack([features_tensor for _ in range(num_taus)], dim=0).reshape(\n",
    "            num_taus * Xshape,\n",
    "            1, -1)\n",
    "        with torch.no_grad():\n",
    "            if onlyGauss:\n",
    "                scoreEval_vec_Z_taus = torch.randn_like(vec_Z_taus).to(device)\n",
    "            else:\n",
    "                scoreEval_vec_Z_taus = vec_Z_taus\n",
    "            vec_predicted_score = good.forward(inputs=scoreEval_vec_Z_taus, times=vec_diff_times, conditioner=vec_conditioner,\n",
    "                                             eff_times=vec_eff_times)\n",
    "        \n",
    "        beta_taus = torch.exp(-0.5 * eff_times[0, 0, 0]).to(device)\n",
    "        sigma_taus = torch.pow(1. - torch.pow(beta_taus, 2), 0.5).to(device)\n",
    "        sigma2_taus=torch.pow(1. - torch.pow(beta_taus, 2), 1.).to(device)\n",
    "        predicted_score = -scoreEval_vec_Z_taus/sigma2_taus + (beta_taus/sigma2_taus)*vec_predicted_score\n",
    "        vec_scores, vec_drift, vec_diffParam = diffusion.get_conditional_reverse_diffusion(x=vec_Z_taus,\n",
    "                                                                                           predicted_score=predicted_score,\n",
    "                                                                                           diff_index=torch.Tensor(\n",
    "                                                                                               [int((\n",
    "                                                                                                       num_diff_times - 1 - difftime_idx))]).to(\n",
    "                                                                                               device),\n",
    "                                                                                           max_diff_steps=Ndiff_discretisation)\n",
    "\n",
    "        if \"PM\" in config.scoreNet_trained_path:\n",
    "            final_mu_hats = (beta_taus*scoreEval_vec_Z_taus / (sigma2_taus)) + ((\n",
    "                                                                            (torch.pow(sigma_taus, 2) + (\n",
    "                                                                                    torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                            2) * ts_step)) / (\n",
    "                                                                                    ts_step * sigma2_taus)) * vec_predicted_score)            \n",
    "        else:\n",
    "            final_mu_hats = (scoreEval_vec_Z_taus / (ts_step * beta_taus)) + ((\n",
    "                                                                            (sigma2_taus + (\n",
    "                                                                                    torch.pow(beta_taus * config.diffusion,\n",
    "                                                                                            2) * ts_step)) / (\n",
    "                                                                                    ts_step * beta_taus)) * vec_scores)\n",
    "\n",
    "        assert (final_mu_hats.shape == (num_taus * Xshape, 1, config.ts_dims))\n",
    "        means = final_mu_hats.reshape((num_taus, Xshape, config.ts_dims))\n",
    "\n",
    "        # print(vec_Z_taus.shape, vec_scores.shape)\n",
    "        final_vec_mu_hats[:, insert_idx,:, :] = means.permute((1, 0, 2)).cpu().numpy()\n",
    "        vec_z = torch.randn_like(vec_drift).to(device)\n",
    "        vec_Z_taus = vec_drift + vec_diffParam * vec_z\n",
    "        insert_idx -=1\n",
    "    assert (final_vec_mu_hats.shape == (Xshape, es, num_taus, config.ts_dims))\n",
    "    return final_vec_mu_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xshape = config.ts_length\n",
    "if config.ndims == 12:\n",
    "    Xs = np.concatenate([np.linspace(-5, 5, num=Xshape).reshape(-1,1), np.linspace(-4.7, 4.7, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-4.4, 4.4, num=Xshape).reshape(-1,1), np.linspace(-4.2, 4.2, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-4.05, 4.05, num=Xshape).reshape(-1,1), np.linspace(-3.9, 3.9, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-3.7, 3.7, num=Xshape).reshape(-1,1), np.linspace(-3.6, 3.6, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-3.55, 3.55, num=Xshape).reshape(-1,1),\n",
    "                            np.linspace(-3.48, 3.48, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-3.4, 3.4, num=Xshape).reshape(-1,1), np.linspace(-3.4, 3.4, num=Xshape).reshape(-1,1)],\n",
    "                        axis=1)\n",
    "elif config.ndims == 8:\n",
    "    Xs = np.concatenate([np.linspace(-4.9, 4.9, num=Xshape).reshape(-1, 1), np.linspace(-4.4, 4.4, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-4.05, 4.05, num=Xshape).reshape(-1,1), np.linspace(-3.9, 3.9, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-3.7, 3.7, num=Xshape).reshape(-1,1), np.linspace(-3.6, 3.6, num=Xshape).reshape(-1,1), \\\n",
    "                            np.linspace(-3.5, 3.5, num=Xshape).reshape(-1,1), np.linspace(-3.4, 3.4, num=Xshape).reshape(-1,1)],\n",
    "                        axis=1)\n",
    "true_drifts = -(4. * np.array(config.quartic_coeff) * np.power(Xs,\n",
    "                                                                           3) + 2. * np.array(\n",
    "                    config.quad_coeff) * Xs + np.array(config.const))\n",
    "true_drifts /= (1+config.deltaT*np.abs(true_drifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote_file_path = project_config.ROOT_DIR+\"data/\" #/Users/marcos/Library/CloudStorage/OneDrive-ImperialCollegeLondon/StatML_CDT/Year2/DiffusionModels/ExperimentResults/\"\n",
    "remote_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "es=0\n",
    "DNonGauss = experiment_MLP_1D_drifts(good=scoreModel,es=es, Xs=Xs, config=config, onlyGauss=False)\n",
    "np.save(remote_file_path + \"8DDimsBiPot_optimal_tau_experiment_DNonGauss.npy\", DNonGauss)\n",
    "\n",
    "DGauss = experiment_MLP_1D_drifts(good=scoreModel,es=es, Xs=Xs, config=config, onlyGauss=True)\n",
    "np.save(remote_file_path + \"8DDimsBiPot_optimal_tau_experiment_DGauss.npy\", DGauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_MSE_CIs(muhats, true_drifts):\n",
    "    estimates = np.mean(muhats, axis=2)\n",
    "    errors = estimates - true_drifts[:, np.newaxis,:]\n",
    "    deltas = (muhats) - estimates[:,:, np.newaxis,:]\n",
    "    #norms = np.sqrt(np.sum(np.power(errors,2), axis=-1, keepdims=True))\n",
    "    us = errors#/norms\n",
    "    us = 2*us.transpose((1,0,2))\n",
    "    deltas = deltas.transpose((1,0,2,3))\n",
    "    val=np.mean(np.sum(us[:, :, np.newaxis, :]*deltas,axis=-1) ,axis=1)\n",
    "    std = np.std(val, axis=-1)\n",
    "    mse = np.mean((np.sum(np.power(errors,2), axis=-1)), axis=0)\n",
    "    return mse, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNonGauss=np.load(remote_file_path + \"8DDimsBiPot_optimal_tau_experiment_DNonGauss.npy\", allow_pickle=True)\n",
    "DGauss=np.load(remote_file_path + \"8DDimsBiPot_optimal_tau_experiment_DGauss.npy\", allow_pickle=True)\n",
    "NonGauss_mse, NonGauss_std = compute_MSE_CIs(muhats=DNonGauss,true_drifts=true_drifts)\n",
    "Gauss_mse, Gauss_std = compute_MSE_CIs(muhats=DGauss,true_drifts=true_drifts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "startidx=0\n",
    "diff_times = np.linspace(config.train_eps, 1, config.max_diff_steps)\n",
    "print(diff_times)\n",
    "plt.scatter(diff_times[startidx:],Gauss_mse[startidx:],s=1, label=\"Gaussian Sampling\")\n",
    "plt.errorbar(x=diff_times[startidx:],y=Gauss_mse[startidx:], yerr=Gauss_std[startidx:], alpha=0.05)\n",
    "plt.scatter(diff_times[startidx:],NonGauss_mse[startidx:],s=1, label=\"Reverse Diffusion\")\n",
    "plt.errorbar(x=diff_times[startidx:],y=NonGauss_mse[startidx:], yerr=NonGauss_std[startidx:], alpha=0.05)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Drift MSE for $\\mu_3$\", fontsize=40)\n",
    "plt.xlabel(rf\"Diffusion Time $\\tau$\", fontsize=38)\n",
    "plt.ylabel(\"Drift MSE\",fontsize=38)\n",
    "ax.tick_params(labelsize=48)\n",
    "plt.grid(True)\n",
    "plt.legend(markerscale=10,fontsize=24)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "startidx=6000\n",
    "diff_times = np.linspace(config.train_eps, 1, config.max_diff_steps)\n",
    "print(diff_times)\n",
    "plt.scatter(diff_times[startidx:],Gauss_mse[startidx:],s=1, label=\"Gaussian Sampling\")\n",
    "plt.errorbar(x=diff_times[startidx:],y=Gauss_mse[startidx:], yerr=Gauss_std[startidx:], alpha=0.05)\n",
    "plt.scatter(diff_times[startidx:],NonGauss_mse[startidx:],s=1, label=\"Reverse Diffusion\")\n",
    "plt.errorbar(x=diff_times[startidx:],y=NonGauss_mse[startidx:], yerr=NonGauss_std[startidx:], alpha=0.05)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Drift MSE for $\\mu_3$\", fontsize=40)\n",
    "plt.xlabel(rf\"Diffusion Time $\\tau$\", fontsize=38)\n",
    "plt.ylabel(\"Drift MSE\",fontsize=38)\n",
    "ax.tick_params(labelsize=48)\n",
    "ax.tick_params(axis=\"y\",which=\"minor\", labelsize=38)\n",
    "plt.grid(True)\n",
    "plt.legend(markerscale=10,fontsize=24)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauidx = 9999\n",
    "tau_NonGauss = DNonGauss[:, tauidx, :, :]\n",
    "estimate = np.mean(tau_NonGauss, axis=1)\n",
    "for d in range(tau_NonGauss.shape[-1]):\n",
    "    fig, ax = plt.subplots(figsize=(14,9))\n",
    "    plt.scatter(Xs[:,d], true_drifts[:, d], color=\"red\", label=\"True Drift\")\n",
    "    plt.scatter(Xs[:,d], estimate[:, d], label=\"Estimated Drift\",color=\"blue\")\n",
    "    lowq_tau_errors = np.quantile(tau_NonGauss[:, :, d], q=0.1, axis=-1)\n",
    "    highq_tau_errors = np.quantile(tau_NonGauss[:, :, d], q=0.9, axis=-1)\n",
    "    plt.fill_between(Xs[:,d],lowq_tau_errors, highq_tau_errors, alpha=0.4,color=\"blue\")\n",
    "    print((np.mean(np.sum(np.power(estimate[:,d]-true_drifts[:,d],2), axis=-1))))\n",
    "    plt.title(rf\"Score Estimator for $\\mu_3$ at $\\tau=${round(diff_times[tauidx],3)}\", fontsize=40)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=24)\n",
    "    ax.tick_params(labelsize=38)\n",
    "    plt.ylabel(\"Drift Value\", fontsize=38)\n",
    "    plt.xlabel(rf\"State $Y$\", fontsize=38)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauidx = 1000\n",
    "tau_NonGauss = DNonGauss[:, tauidx, :, :]\n",
    "estimate = np.mean(tau_NonGauss, axis=1)\n",
    "for d in range(tau_NonGauss.shape[-1]):\n",
    "    fig, ax = plt.subplots(figsize=(14,9))\n",
    "    plt.scatter(Xs[:,d], true_drifts[:, d], color=\"red\",label=\"True Drift\")\n",
    "    plt.scatter(Xs[:,d], estimate[:, d], label=\"Estimated Drift\",color=\"blue\")\n",
    "    lowq_tau_errors = np.quantile(tau_NonGauss[:, :, d], q=0.1, axis=-1)\n",
    "    highq_tau_errors = np.quantile(tau_NonGauss[:, :, d], q=0.9, axis=-1)\n",
    "    plt.fill_between(Xs[:,d],lowq_tau_errors, highq_tau_errors, alpha=0.4,color=\"blue\")\n",
    "    print((np.mean(np.sum(np.power(estimate[:,d]-true_drifts[:,d],2), axis=-1))))\n",
    "    plt.title(rf\"Score Estimator for $\\mu_3$ at $\\tau=${round(diff_times[tauidx],3)}\", fontsize=40)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=24)\n",
    "    ax.tick_params(labelsize=38)\n",
    "    plt.ylabel(\"Drift Value\", fontsize=38)\n",
    "    plt.xlabel(rf\"State $Y$\", fontsize=38)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
